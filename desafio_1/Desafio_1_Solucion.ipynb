{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d584e2",
   "metadata": {},
   "source": [
    "# Desafío 1 - Solución\n",
    "\n",
    "## Paola Cartalá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a613f3",
   "metadata": {},
   "source": [
    "### Consigna desafio 1\n",
    "\n",
    "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
    "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
    "\n",
    "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
    "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
    "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
    "y ComplementNB.\n",
    "\n",
    "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
    "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
    "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ff2e4",
   "metadata": {},
   "source": [
    "### Obtención y procesamiento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b31a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyPDF2 numpy scikit-learn pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5ac212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971e2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(ruta_pdf):\n",
    "    \"\"\"\n",
    "    Extrae texto de un archivo PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ruta_pdf, 'rb') as archivo:\n",
    "            lector_pdf = PyPDF2.PdfReader(archivo)\n",
    "            texto_completo = \"\"\n",
    "            \n",
    "            print(f\"Procesando: {os.path.basename(ruta_pdf)} ({len(lector_pdf.pages)} páginas)\")\n",
    "            \n",
    "            for pagina in tqdm(lector_pdf.pages, desc=\"Extrayendo páginas\"):\n",
    "                try:\n",
    "                    texto_pagina = pagina.extract_text()\n",
    "                    if texto_pagina:\n",
    "                        texto_completo += texto_pagina + \"\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error en página: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return texto_completo\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {ruta_pdf}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6aeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_libros(carpeta_data=\"data\"):\n",
    "    \"\"\"\n",
    "    Procesa todos los libros de la carpeta data.\n",
    "    \"\"\"\n",
    "    libros = []\n",
    "    \n",
    "    patron_pdf = os.path.join(carpeta_data, \"*.pdf\")\n",
    "    archivos_pdf = glob.glob(patron_pdf)\n",
    "    \n",
    "    if not archivos_pdf:\n",
    "        print(f\"No se encontraron archivos PDF en la carpeta {carpeta_data}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Encontrados {len(archivos_pdf)} libros:\")\n",
    "    for archivo in archivos_pdf:\n",
    "        print(f\"  - {os.path.basename(archivo)}\")\n",
    "    \n",
    "    for archivo_pdf in archivos_pdf:\n",
    "        nombre_libro = os.path.splitext(os.path.basename(archivo_pdf))[0]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Procesando: {nombre_libro}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        texto = extraer_texto_pdf(archivo_pdf)\n",
    "        \n",
    "        if texto and len(texto.strip()) > 100:\n",
    "            libros.append({\n",
    "                'titulo': nombre_libro,\n",
    "                'archivo': archivo_pdf,\n",
    "                'texto': texto,\n",
    "                'num_caracteres': len(texto),\n",
    "                'num_palabras': len(texto.split())\n",
    "            })\n",
    "            print(f\"✓ Texto extraído: {len(texto):,} caracteres, {len(texto.split()):,} palabras\")\n",
    "        else:\n",
    "            print(f\"✗ No se pudo extraer texto del archivo\")\n",
    "    \n",
    "    print(f\"\\nProcesamiento completado. {len(libros)} libros procesados exitosamente.\")\n",
    "    return libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b028927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 5 libros:\n",
      "  - El visitante - Stephen King.pdf\n",
      "  - Fin de guardia - Stephen King.pdf\n",
      "  - Holly - Stephen King.pdf\n",
      "  - Mr Mercedes - Stephen King.pdf\n",
      "  - Quien pierde paga - Stephen King.pdf\n",
      "\n",
      "============================================================\n",
      "Procesando: El visitante - Stephen King\n",
      "============================================================\n",
      "Procesando: El visitante - Stephen King.pdf (478 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo páginas: 100%|██████████| 478/478 [00:27<00:00, 17.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Texto extraído: 1,000,020 caracteres, 175,368 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Fin de guardia - Stephen King\n",
      "============================================================\n",
      "Procesando: Fin de guardia - Stephen King.pdf (291 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo páginas: 100%|██████████| 291/291 [00:16<00:00, 18.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Texto extraído: 731,770 caracteres, 128,323 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Holly - Stephen King\n",
      "============================================================\n",
      "Procesando: Holly - Stephen King.pdf (431 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo páginas: 100%|██████████| 431/431 [00:19<00:00, 22.00it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Texto extraído: 882,615 caracteres, 157,563 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Mr Mercedes - Stephen King\n",
      "============================================================\n",
      "Procesando: Mr Mercedes - Stephen King.pdf (345 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo páginas: 100%|██████████| 345/345 [00:23<00:00, 14.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Texto extraído: 851,392 caracteres, 150,535 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Quien pierde paga - Stephen King\n",
      "============================================================\n",
      "Procesando: Quien pierde paga - Stephen King.pdf (349 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo páginas: 100%|██████████| 349/349 [00:23<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Texto extraído: 784,435 caracteres, 138,061 palabras\n",
      "\n",
      "Procesamiento completado. 5 libros procesados exitosamente.\n",
      "\n",
      "Se procesaron 5 libros de Stephen King\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "libros_stephen_king = procesar_libros()\n",
    "print(f\"\\nSe procesaron {len(libros_stephen_king)} libros de Stephen King\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a03e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadatos guardados en stephen_king_metadata.json\n"
     ]
    }
   ],
   "source": [
    "libros_metadata = []\n",
    "for libro in libros_stephen_king:\n",
    "    libros_metadata.append({\n",
    "        'titulo': libro['titulo'],\n",
    "        'archivo': libro['archivo'],\n",
    "        'num_caracteres': libro['num_caracteres'],\n",
    "        'num_palabras': libro['num_palabras']\n",
    "    })\n",
    "\n",
    "with open('stephen_king_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(libros_metadata, f, ensure_ascii=False, indent=2)\n",
    "print(\"Metadatos guardados en stephen_king_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bcd217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de documentos (capítulos) para análisis: 36\n"
     ]
    }
   ],
   "source": [
    "def dividir_en_capitulos(texto, titulo_libro, tamaño_min_capitulo=2000):\n",
    "    \"\"\"\n",
    "    Divide un libro en capítulos o secciones basándose en patrones comunes.\n",
    "    \"\"\"\n",
    "    patrones_capitulo = [\n",
    "        r'\\n\\s*(?:CAPÍTULO|CAPITULO|Chapter)\\s+[IVXLCDM\\d]+[^\\n]*\\n',\n",
    "        r'\\n\\s*\\d+\\s*\\n\\n',\n",
    "        r'\\n\\s*[IVXLCDM]+\\s*\\n\\n',\n",
    "        r'\\n\\s*(?:PARTE|PART)\\s+[IVXLCDM\\d]+[^\\n]*\\n'\n",
    "    ]\n",
    "    \n",
    "    capitulos = []\n",
    "    texto_restante = texto\n",
    "    \n",
    "    for patron in patrones_capitulo:\n",
    "        divisiones = re.split(patron, texto_restante, flags=re.IGNORECASE)\n",
    "        if len(divisiones) > 2:  # Si encontró divisiones útiles\n",
    "            for i, division in enumerate(divisiones):\n",
    "                if len(division.strip()) > tamaño_min_capitulo:\n",
    "                    capitulos.append({\n",
    "                        'libro': titulo_libro,\n",
    "                        'capitulo': i + 1,\n",
    "                        'texto': division.strip()\n",
    "                    })\n",
    "            break\n",
    "    \n",
    "    if not capitulos:\n",
    "        palabras = texto.split()\n",
    "        tamaño_chunk = 3000\n",
    "        \n",
    "        for i in range(0, len(palabras), tamaño_chunk):\n",
    "            chunk = ' '.join(palabras[i:i + tamaño_chunk])\n",
    "            if len(chunk.strip()) > tamaño_min_capitulo:\n",
    "                capitulos.append({\n",
    "                    'libro': titulo_libro,\n",
    "                    'capitulo': i // tamaño_chunk + 1,\n",
    "                    'texto': chunk.strip()\n",
    "                })\n",
    "    \n",
    "    return capitulos\n",
    "\n",
    "todos_los_documentos = []\n",
    "\n",
    "for libro in libros_stephen_king:\n",
    "    capitulos = dividir_en_capitulos(libro['texto'], libro['titulo'])\n",
    "    todos_los_documentos.extend(capitulos)\n",
    "\n",
    "print(f\"\\nTotal de documentos (capítulos) para análisis: {len(todos_los_documentos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a426b",
   "metadata": {},
   "source": [
    "#### Preparación de datos para el análisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d45bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se prepararon 36 textos para análisis\n"
     ]
    }
   ],
   "source": [
    "def preparar_textos(documentos):\n",
    "    \"\"\"\n",
    "    Prepara los textos de los capítulos para análisis de NLP.\n",
    "    \"\"\"\n",
    "    textos = []\n",
    "    metadatos = []\n",
    "    \n",
    "    for doc in documentos:\n",
    "        texto_limpio = re.sub(r'\\s+', ' ', doc['texto']).strip()\n",
    "        \n",
    "        if len(texto_limpio) > 100:\n",
    "            textos.append(texto_limpio)\n",
    "            metadatos.append({\n",
    "                'libro': doc['libro'],\n",
    "                'capitulo': doc['capitulo'],\n",
    "                'num_palabras': len(texto_limpio.split())\n",
    "            })\n",
    "    \n",
    "    return textos, metadatos\n",
    "\n",
    "textos_stephen_king, metadatos_stephen_king = preparar_textos(todos_los_documentos)\n",
    "\n",
    "print(f\"Se prepararon {len(textos_stephen_king)} textos para análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447d602",
   "metadata": {},
   "source": [
    "### 1: Vectorización y análisis de similaridad de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d655731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz documento-término creada:\n",
      "Forma: (36, 5000)\n",
      "Cantidad de documentos (capítulos): 36\n",
      "Tamaño del vocabulario: 5000\n",
      "Densidad de la matriz: 0.4904\n",
      "\n",
      "Ejemplos de términos en el vocabulario:\n",
      "['once', 'asesinado', 'pruebas', 'flint', 'city', 'terry', 'maitland', 'entrenador', 'liga', 'infantil', 'profesor', 'literatura', 'marido', 'ejemplar', 'niñas', 'detective', 'ralph', 'anderson', 'detención', 'firme']\n"
     ]
    }
   ],
   "source": [
    "tfidfvect = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words=None,\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_stephen_king = tfidfvect.fit_transform(textos_stephen_king)\n",
    "\n",
    "print(f\"Matriz documento-término creada:\")\n",
    "print(f\"Forma: {X_stephen_king.shape}\")\n",
    "print(f\"Cantidad de documentos (capítulos): {X_stephen_king.shape[0]}\")\n",
    "print(f\"Tamaño del vocabulario: {X_stephen_king.shape[1]}\")\n",
    "print(f\"Densidad de la matriz: {X_stephen_king.nnz / (X_stephen_king.shape[0] * X_stephen_king.shape[1]):.4f}\")\n",
    "\n",
    "print(f\"\\nEjemplos de términos en el vocabulario:\")\n",
    "vocabulario_ejemplo = list(tfidfvect.vocabulary_.keys())[:20]\n",
    "print(vocabulario_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79952933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos (capítulos) seleccionados para análisis de similaridad:\n",
      "\n",
      "1. Documento 35\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Capítulo: 5\n",
      "   Palabras: 42190\n",
      "   Texto (primeros 150 chars): El Padrino , pero es también una buena frase. Una de las mejores. Envía el dinero. Se queda el cuaderno. Un cuaderno caro que metió bajo la almohada c...\n",
      "\n",
      "2. Documento 13\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 4\n",
      "   Palabras: 22203\n",
      "   Texto (primeros 150 chars): —Ajá. Me ha dicho que empezó a notar a la señora Ellerton retraída… —Un poco retraída —rectifica la señora Alderson al instante—. En general, era la d...\n",
      "\n",
      "3. Documento 26\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 4\n",
      "   Palabras: 8587\n",
      "   Texto (primeros 150 chars): 17 Ese primer interrogatorio crucial, solo unas horas después del crimen. Café y pastas mientras los cuerpos destrozados de los muertos eran identific...\n",
      "\n",
      "4. Documento 30\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 8\n",
      "   Palabras: 54226\n",
      "   Texto (primeros 150 chars): llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué ser...\n",
      "\n",
      "5. Documento 16\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 7\n",
      "   Palabras: 37317\n",
      "   Texto (primeros 150 chars): A juzgar por su voz, Pete parece cansado. —Hemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste tú cuando empeza...\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "indices_seleccionados = np.random.choice(len(textos_stephen_king), 5, replace=False)\n",
    "\n",
    "print(\"Documentos (capítulos) seleccionados para análisis de similaridad:\")\n",
    "for i, idx in enumerate(indices_seleccionados):\n",
    "    metadata = metadatos_stephen_king[idx]\n",
    "    print(f\"\\n{i+1}. Documento {idx}\")\n",
    "    print(f\"   Libro: {metadata['libro']}\")\n",
    "    print(f\"   Capítulo: {metadata['capitulo']}\")\n",
    "    print(f\"   Palabras: {metadata['num_palabras']}\")\n",
    "    print(f\"   Texto (primeros 150 chars): {textos_stephen_king[idx][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3261cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - DOCUMENTO 35\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Quien pierde paga - Stephen King\n",
      "Capítulo: 5\n",
      "Palabras: 42190\n",
      "Texto: El Padrino , pero es también una buena frase. Una de las mejores. Envía el dinero. Se queda el cuaderno. Un cuaderno caro que metió bajo la almohada cuando la hermana menor apareció de improviso en la...\n",
      "\n",
      "TOP 5 DOCUMENTOS MÁS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.6663 📖 MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Capítulo: 4\n",
      "   Texto: atención. Me contrataron para encontrar el avión y tomar posesión de él. Eso es todo, punto y final. No trabajo para el FBI ni para el Departamento de...\n",
      "\n",
      "2. Similaridad: 0.5809 📖 MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: candado enorme. Agarró de nuevo el asa, y esta vez se partió. —¡La puta! —exclamó Pete, y se miró las manos. Las tenía rojas y palpitantes. Bueno, de ...\n",
      "\n",
      "3. Similaridad: 0.5004 📚 OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 8\n",
      "   Texto: llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué ser...\n",
      "\n",
      "4. Similaridad: 0.4677 📚 OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: está llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. —Perdonen —dice a la sala en general—. Un mensaje de texto. —Y muy ...\n",
      "\n",
      "5. Similaridad: 0.4583 📖 MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Capítulo: 1\n",
      "   Texto: «Despierta, genio». Así comienza la fascinante nueva novela de Stephen King sobre un lector fanático. El genio es John Rothstein, un autor de culto, c...\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - DOCUMENTO 13\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Fin de guardia - Stephen King\n",
      "Capítulo: 4\n",
      "Palabras: 22203\n",
      "Texto: —Ajá. Me ha dicho que empezó a notar a la señora Ellerton retraída… —Un poco retraída —rectifica la señora Alderson al instante—. En general, era la de siempre. Rebosaba amor, igual que Marty. —Pero a...\n",
      "\n",
      "TOP 5 DOCUMENTOS MÁS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.7139 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: bueno, hacerte daño… llámame. Llámame inmediatamente . —Vale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "2. Similaridad: 0.6917 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 6\n",
      "   Texto: luego se quedan vidriosos. —Vaya aguante —comenta Brady, casi con afecto. Se abre una puerta. Los pasos de unos pies calzados con zapatillas se acerca...\n",
      "\n",
      "3. Similaridad: 0.6759 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 7\n",
      "   Texto: A juzgar por su voz, Pete parece cansado. —Hemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste tú cuando empeza...\n",
      "\n",
      "4. Similaridad: 0.6079 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: está llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. —Perdonen —dice a la sala en general—. Un mensaje de texto. —Y muy ...\n",
      "\n",
      "5. Similaridad: 0.5848 📚 OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 8\n",
      "   Texto: llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué ser...\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - DOCUMENTO 26\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Mr Mercedes - Stephen King\n",
      "Capítulo: 4\n",
      "Palabras: 8587\n",
      "Texto: 17 Ese primer interrogatorio crucial, solo unas horas después del crimen. Café y pastas mientras los cuerpos destrozados de los muertos eran identificados. En algún lugar los familiares lloraban y se ...\n",
      "\n",
      "TOP 5 DOCUMENTOS MÁS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.6940 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: menos en la mayoría de los casos. Es un don que Pete Huntley jamás ha poseído, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n",
      "\n",
      "2. Similaridad: 0.6451 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 3\n",
      "   Texto: silencio Pete dice: —Pues que esta vez sea una celebración solo para hombres. —Tú mismo —contesta Hodges con alivio—. Esperaré impaciente. —Yo también...\n",
      "\n",
      "3. Similaridad: 0.5670 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 8\n",
      "   Texto: llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué ser...\n",
      "\n",
      "4. Similaridad: 0.5065 📚 OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: está llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. —Perdonen —dice a la sala en general—. Un mensaje de texto. —Y muy ...\n",
      "\n",
      "5. Similaridad: 0.4817 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: televisión de acceso público, recurso olvidado por muchos), y casualmente me enteré de que a la noche siguiente se celebró una fiesta en el Raintree I...\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - DOCUMENTO 30\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Mr Mercedes - Stephen King\n",
      "Capítulo: 8\n",
      "Palabras: 54226\n",
      "Texto: llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué serviría? Esa parte de su vida ha terminado. Pronto t...\n",
      "\n",
      "TOP 5 DOCUMENTOS MÁS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.7057 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: menos en la mayoría de los casos. Es un don que Pete Huntley jamás ha poseído, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n",
      "\n",
      "2. Similaridad: 0.6576 📚 OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 7\n",
      "   Texto: A juzgar por su voz, Pete parece cansado. —Hemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste tú cuando empeza...\n",
      "\n",
      "3. Similaridad: 0.6485 📖 MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 6\n",
      "   Texto: guantera. —Creo que las opciones de asesinato pasan por la cabeza de este individuo tan deprisa como salen los naipes de las manos de un buen repartid...\n",
      "\n",
      "4. Similaridad: 0.6484 📚 OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: bueno, hacerte daño… llámame. Llámame inmediatamente . —Vale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "5. Similaridad: 0.6328 📚 OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 2\n",
      "   Texto: está llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. —Perdonen —dice a la sala en general—. Un mensaje de texto. —Y muy ...\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - DOCUMENTO 16\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Fin de guardia - Stephen King\n",
      "Capítulo: 7\n",
      "Palabras: 37317\n",
      "Texto: A juzgar por su voz, Pete parece cansado. —Hemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste tú cuando empezamos a trabajar juntos: que el caso manda, y vas a ...\n",
      "\n",
      "TOP 5 DOCUMENTOS MÁS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.8257 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 6\n",
      "   Texto: luego se quedan vidriosos. —Vaya aguante —comenta Brady, casi con afecto. Se abre una puerta. Los pasos de unos pies calzados con zapatillas se acerca...\n",
      "\n",
      "2. Similaridad: 0.7295 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: bueno, hacerte daño… llámame. Llámame inmediatamente . —Vale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "3. Similaridad: 0.6759 📖 MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Capítulo: 4\n",
      "   Texto: —Ajá. Me ha dicho que empezó a notar a la señora Ellerton retraída… —Un poco retraída —rectifica la señora Alderson al instante—. En general, era la d...\n",
      "\n",
      "4. Similaridad: 0.6576 📚 OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 8\n",
      "   Texto: llegado el raticida que encargó con el alias de Ralph Jones, pero tiene la sensación de que han pasado mil años desde entonces, y de hecho ¿de qué ser...\n",
      "\n",
      "5. Similaridad: 0.5503 📚 OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Capítulo: 5\n",
      "   Texto: menos en la mayoría de los casos. Es un don que Pete Huntley jamás ha poseído, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n"
     ]
    }
   ],
   "source": [
    "def analizar_similaridad_documento(idx, X, textos, metadatos, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad de un capítulo con todos los demás capítulos.\n",
    "    \"\"\"\n",
    "    similaridades = cosine_similarity(X[idx], X)[0]\n",
    "    \n",
    "    indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANÁLISIS DE SIMILARIDAD - DOCUMENTO {idx}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    metadata_orig = metadatos[idx]\n",
    "    print(f\"\\nDOCUMENTO ORIGINAL:\")\n",
    "    print(f\"Libro: {metadata_orig['libro']}\")\n",
    "    print(f\"Capítulo: {metadata_orig['capitulo']}\")\n",
    "    print(f\"Palabras: {metadata_orig['num_palabras']}\")\n",
    "    print(f\"Texto: {textos[idx][:200]}...\")\n",
    "    \n",
    "    print(f\"\\nTOP {top_k} DOCUMENTOS MÁS SIMILARES:\")\n",
    "    for i, idx_sim in enumerate(indices_similares):\n",
    "        metadata_sim = metadatos[idx_sim]\n",
    "        sim_score = similaridades[idx_sim]\n",
    "        \n",
    "        mismo_libro = metadata_sim['libro'] == metadata_orig['libro']\n",
    "        indicador = \"📖 MISMO LIBRO\" if mismo_libro else \"📚 OTRO LIBRO\"\n",
    "        \n",
    "        print(f\"\\n{i+1}. Similaridad: {sim_score:.4f} {indicador}\")\n",
    "        print(f\"   Libro: {metadata_sim['libro']}\")\n",
    "        print(f\"   Capítulo: {metadata_sim['capitulo']}\")\n",
    "        print(f\"   Texto: {textos[idx_sim][:150]}...\")\n",
    "    \n",
    "    return indices_similares, similaridades[indices_similares]\n",
    "\n",
    "for idx in indices_seleccionados:\n",
    "    analizar_similaridad_documento(idx, X_stephen_king, textos_stephen_king, metadatos_stephen_king)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e7290",
   "metadata": {},
   "source": [
    "### 2: Optimización de modelos Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55926f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33cf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_clasificacion_libros(textos, metadatos, min_capitulos_por_libro=3):\n",
    "    \"\"\"\n",
    "    Prepara los datos para clasificación por libro.\n",
    "    \"\"\"\n",
    "    conteo_libros = {}\n",
    "    for metadata in metadatos:\n",
    "        libro = metadata['libro']\n",
    "        conteo_libros[libro] = conteo_libros.get(libro, 0) + 1\n",
    "    \n",
    "    libros_validos = {libro for libro, count in conteo_libros.items() \n",
    "                     if count >= min_capitulos_por_libro}\n",
    "    \n",
    "    textos_filtrados = []\n",
    "    etiquetas = []\n",
    "    metadatos_filtrados = []\n",
    "    \n",
    "    for i, metadata in enumerate(metadatos):\n",
    "        if metadata['libro'] in libros_validos:\n",
    "            textos_filtrados.append(textos[i])\n",
    "            etiquetas.append(metadata['libro'])\n",
    "            metadatos_filtrados.append(metadata)\n",
    "    \n",
    "    return textos_filtrados, etiquetas, metadatos_filtrados, libros_validos\n",
    "\n",
    "textos_clf, etiquetas_clf, metadatos_clf, libros_validos = preparar_datos_clasificacion_libros(\n",
    "    textos_stephen_king, metadatos_stephen_king, min_capitulos_por_libro=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba1d93",
   "metadata": {},
   "source": [
    "#### Análisis de etiquetado temático y de personajes\n",
    "\n",
    "Vamos a enriquecer la clasificación identificando temas y personajes principales en los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5603fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_temas_personajes(textos, metadatos):\n",
    "    \"\"\"\n",
    "    Detecta temas y personajes principales en los textos basándose en palabras clave.\n",
    "    \"\"\"\n",
    "    # Definir diccionarios de temas y personajes conocidos de Stephen King\n",
    "    temas_keywords = {\n",
    "        'horror_supernatural': ['fantasma', 'demonio', 'espíritu', 'supernatural', 'maldición', 'aparición', 'sobrenatural'],\n",
    "        'crimen_detective': ['detective', 'policía', 'asesino', 'crimen', 'investigación', 'homicidio', 'caso'],\n",
    "        'psicológico': ['mente', 'loco', 'psicólogo', 'mental', 'locura', 'cerebro', 'pensamiento'],\n",
    "        'terror_urbano': ['ciudad', 'calle', 'hospital', 'hotel', 'edificio', 'urbano'],\n",
    "        'muerte_violencia': ['muerte', 'sangre', 'matar', 'violencia', 'cadáver', 'asesinato']\n",
    "    }\n",
    "    \n",
    "    personajes_keywords = {\n",
    "        'bill_hodges': ['hodges', 'bill', 'detective hodges', 'william hodges'],\n",
    "        'holly_gibney': ['holly', 'gibney', 'holly gibney'],\n",
    "        'jerome_robinson': ['jerome', 'robinson'],\n",
    "        'brady_hartsfield': ['brady', 'hartsfield', 'mr mercedes'],\n",
    "        'ralph_anderson': ['ralph', 'anderson'],\n",
    "        'el_visitante': ['visitante', 'outsider', 'extraño']\n",
    "    }\n",
    "    \n",
    "    textos_etiquetados = []\n",
    "    \n",
    "    for i, texto in enumerate(textos):\n",
    "        texto_lower = texto.lower()\n",
    "        metadata = metadatos[i].copy()\n",
    "        \n",
    "        # Detectar temas\n",
    "        temas_detectados = []\n",
    "        for tema, keywords in temas_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in texto_lower)\n",
    "            if score > 0:\n",
    "                temas_detectados.append((tema, score))\n",
    "        \n",
    "        # Detectar personajes\n",
    "        personajes_detectados = []\n",
    "        for personaje, keywords in personajes_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in texto_lower)\n",
    "            if score > 0:\n",
    "                personajes_detectados.append((personaje, score))\n",
    "        \n",
    "        # Ordenar por relevancia\n",
    "        temas_detectados.sort(key=lambda x: x[1], reverse=True)\n",
    "        personajes_detectados.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Agregar etiquetas al metadata\n",
    "        metadata['tema_principal'] = temas_detectados[0][0] if temas_detectados else 'general'\n",
    "        metadata['todos_temas'] = [t[0] for t in temas_detectados]\n",
    "        metadata['personaje_principal'] = personajes_detectados[0][0] if personajes_detectados else 'otros'\n",
    "        metadata['todos_personajes'] = [p[0] for p in personajes_detectados]\n",
    "        \n",
    "        textos_etiquetados.append(metadata)\n",
    "    \n",
    "    return textos_etiquetados\n",
    "\n",
    "# Aplicar etiquetado temático\n",
    "metadatos_enriquecidos = detectar_temas_personajes(textos_stephen_king, metadatos_stephen_king)\n",
    "\n",
    "print(\"Análisis de etiquetado temático y de personajes completado\")\n",
    "print(f\"Ejemplo de metadatos enriquecidos:\")\n",
    "for i in range(min(3, len(metadatos_enriquecidos))):\n",
    "    meta = metadatos_enriquecidos[i]\n",
    "    print(f\"\\nCapítulo {i+1}:\")\n",
    "    print(f\"  Libro: {meta['libro']}\")\n",
    "    print(f\"  Tema principal: {meta['tema_principal']}\")\n",
    "    print(f\"  Personaje principal: {meta['personaje_principal']}\")\n",
    "    print(f\"  Todos los temas: {meta['todos_temas']}\")\n",
    "    print(f\"  Todos los personajes: {meta['todos_personajes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_distribucion_etiquetas(metadatos_enriquecidos):\n",
    "    \"\"\"\n",
    "    Analiza la distribución de temas y personajes en el corpus.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Contar temas principales\n",
    "    temas_principales = [meta['tema_principal'] for meta in metadatos_enriquecidos]\n",
    "    contador_temas = Counter(temas_principales)\n",
    "    \n",
    "    # Contar personajes principales\n",
    "    personajes_principales = [meta['personaje_principal'] for meta in metadatos_enriquecidos]\n",
    "    contador_personajes = Counter(personajes_principales)\n",
    "    \n",
    "    # Contar todos los temas (múltiple por documento)\n",
    "    todos_temas = []\n",
    "    for meta in metadatos_enriquecidos:\n",
    "        todos_temas.extend(meta['todos_temas'])\n",
    "    contador_todos_temas = Counter(todos_temas)\n",
    "    \n",
    "    # Contar todos los personajes (múltiple por documento)\n",
    "    todos_personajes = []\n",
    "    for meta in metadatos_enriquecidos:\n",
    "        todos_personajes.extend(meta['todos_personajes'])\n",
    "    contador_todos_personajes = Counter(todos_personajes)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"DISTRIBUCIÓN DE TEMAS Y PERSONAJES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nTEMAS PRINCIPALES (uno por capítulo):\")\n",
    "    for tema, count in contador_temas.most_common():\n",
    "        porcentaje = (count / len(metadatos_enriquecidos)) * 100\n",
    "        print(f\"  {tema}: {count} capítulos ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nPERSONAJES PRINCIPALES (uno por capítulo):\")\n",
    "    for personaje, count in contador_personajes.most_common():\n",
    "        porcentaje = (count / len(metadatos_enriquecidos)) * 100\n",
    "        print(f\"  {personaje}: {count} capítulos ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTODOS LOS TEMAS DETECTADOS (múltiples por capítulo):\")\n",
    "    for tema, count in contador_todos_temas.most_common():\n",
    "        print(f\"  {tema}: {count} menciones\")\n",
    "    \n",
    "    print(f\"\\nTODOS LOS PERSONAJES DETECTADOS (múltiples por capítulo):\")\n",
    "    for personaje, count in contador_todos_personajes.most_common():\n",
    "        print(f\"  {personaje}: {count} menciones\")\n",
    "    \n",
    "    return contador_temas, contador_personajes\n",
    "\n",
    "# Analizar distribución\n",
    "dist_temas, dist_personajes = analizar_distribucion_etiquetas(metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_clasificadores_enriquecidos(textos, metadatos_enriquecidos):\n",
    "    \"\"\"\n",
    "    Entrena clasificadores para temas y personajes además de libros.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLASIFICACIÓN ENRIQUECIDA: TEMAS Y PERSONAJES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Preparar datos para clasificación por tema\n",
    "    temas = [meta['tema_principal'] for meta in metadatos_enriquecidos]\n",
    "    temas_unicos = list(set(temas))\n",
    "    \n",
    "    if len(temas_unicos) >= 2:\n",
    "        print(f\"\\nClasificación por TEMA:\")\n",
    "        print(f\"Temas disponibles: {temas_unicos}\")\n",
    "        \n",
    "        # Filtrar solo temas con suficientes ejemplos\n",
    "        from collections import Counter\n",
    "        contador_temas = Counter(temas)\n",
    "        temas_validos = [tema for tema, count in contador_temas.items() if count >= 3]\n",
    "        \n",
    "        if len(temas_validos) >= 2:\n",
    "            textos_tema = []\n",
    "            etiquetas_tema = []\n",
    "            \n",
    "            for i, meta in enumerate(metadatos_enriquecidos):\n",
    "                if meta['tema_principal'] in temas_validos:\n",
    "                    textos_tema.append(textos[i])\n",
    "                    etiquetas_tema.append(meta['tema_principal'])\n",
    "            \n",
    "            if len(textos_tema) >= 10:\n",
    "                # Entrenar clasificador de temas\n",
    "                label_encoder_tema = LabelEncoder()\n",
    "                y_tema_encoded = label_encoder_tema.fit_transform(etiquetas_tema)\n",
    "                \n",
    "                X_train_tema, X_test_tema, y_train_tema, y_test_tema = train_test_split(\n",
    "                    textos_tema, y_tema_encoded, test_size=0.3, random_state=42, stratify=y_tema_encoded\n",
    "                )\n",
    "                \n",
    "                # Vectorizar y entrenar\n",
    "                vectorizer_tema = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "                X_train_tema_vec = vectorizer_tema.fit_transform(X_train_tema)\n",
    "                X_test_tema_vec = vectorizer_tema.transform(X_test_tema)\n",
    "                \n",
    "                # Probar modelos\n",
    "                modelo_tema = MultinomialNB(alpha=1.0)\n",
    "                modelo_tema.fit(X_train_tema_vec, y_train_tema)\n",
    "                \n",
    "                y_pred_tema = modelo_tema.predict(X_test_tema_vec)\n",
    "                f1_tema = f1_score(y_test_tema, y_pred_tema, average='macro')\n",
    "                \n",
    "                print(f\"F1-score para clasificación de temas: {f1_tema:.4f}\")\n",
    "                print(\"Reporte de clasificación de temas:\")\n",
    "                print(classification_report(y_test_tema, y_pred_tema, \n",
    "                                          target_names=label_encoder_tema.classes_))\n",
    "        else:\n",
    "            print(\"No hay suficientes temas con ejemplos mínimos para entrenar.\")\n",
    "    \n",
    "    # Preparar datos para clasificación por personaje\n",
    "    personajes = [meta['personaje_principal'] for meta in metadatos_enriquecidos]\n",
    "    personajes_unicos = list(set(personajes))\n",
    "    \n",
    "    if len(personajes_unicos) >= 2:\n",
    "        print(f\"\\nClasificación por PERSONAJE:\")\n",
    "        print(f\"Personajes disponibles: {personajes_unicos}\")\n",
    "        \n",
    "        # Filtrar solo personajes con suficientes ejemplos\n",
    "        contador_personajes = Counter(personajes)\n",
    "        personajes_validos = [personaje for personaje, count in contador_personajes.items() if count >= 3]\n",
    "        \n",
    "        if len(personajes_validos) >= 2:\n",
    "            textos_personaje = []\n",
    "            etiquetas_personaje = []\n",
    "            \n",
    "            for i, meta in enumerate(metadatos_enriquecidos):\n",
    "                if meta['personaje_principal'] in personajes_validos:\n",
    "                    textos_personaje.append(textos[i])\n",
    "                    etiquetas_personaje.append(meta['personaje_principal'])\n",
    "            \n",
    "            if len(textos_personaje) >= 10:\n",
    "                # Entrenar clasificador de personajes\n",
    "                label_encoder_personaje = LabelEncoder()\n",
    "                y_personaje_encoded = label_encoder_personaje.fit_transform(etiquetas_personaje)\n",
    "                \n",
    "                X_train_pers, X_test_pers, y_train_pers, y_test_pers = train_test_split(\n",
    "                    textos_personaje, y_personaje_encoded, test_size=0.3, random_state=42, stratify=y_personaje_encoded\n",
    "                )\n",
    "                \n",
    "                # Vectorizar y entrenar\n",
    "                vectorizer_personaje = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "                X_train_pers_vec = vectorizer_personaje.fit_transform(X_train_pers)\n",
    "                X_test_pers_vec = vectorizer_personaje.transform(X_test_pers)\n",
    "                \n",
    "                # Probar modelos\n",
    "                modelo_personaje = MultinomialNB(alpha=1.0)\n",
    "                modelo_personaje.fit(X_train_pers_vec, y_train_pers)\n",
    "                \n",
    "                y_pred_personaje = modelo_personaje.predict(X_test_pers_vec)\n",
    "                f1_personaje = f1_score(y_test_pers, y_pred_personaje, average='macro')\n",
    "                \n",
    "                print(f\"F1-score para clasificación de personajes: {f1_personaje:.4f}\")\n",
    "                print(\"Reporte de clasificación de personajes:\")\n",
    "                print(classification_report(y_test_pers, y_pred_personaje, \n",
    "                                          target_names=label_encoder_personaje.classes_))\n",
    "        else:\n",
    "            print(\"No hay suficientes personajes con ejemplos mínimos para entrenar.\")\n",
    "\n",
    "# Entrenar clasificadores enriquecidos\n",
    "entrenar_clasificadores_enriquecidos(textos_stephen_king, metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742428ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_similaridad_enriquecida(indices_seleccionados, X, textos, metadatos_enriquecidos, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad considerando las etiquetas temáticas y de personajes.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANÁLISIS DE SIMILARIDAD ENRIQUECIDO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for idx in indices_seleccionados:\n",
    "        similaridades = cosine_similarity(X[idx], X)[0]\n",
    "        indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DOCUMENTO {idx} - ANÁLISIS ENRIQUECIDO\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        metadata_orig = metadatos_enriquecidos[idx]\n",
    "        print(f\"\\nDOCUMENTO ORIGINAL:\")\n",
    "        print(f\"Libro: {metadata_orig['libro']}\")\n",
    "        print(f\"Capítulo: {metadata_orig['capitulo']}\")\n",
    "        print(f\"Tema principal: {metadata_orig['tema_principal']}\")\n",
    "        print(f\"Personaje principal: {metadata_orig['personaje_principal']}\")\n",
    "        print(f\"Todos los temas: {metadata_orig['todos_temas']}\")\n",
    "        print(f\"Texto: {textos[idx][:150]}...\")\n",
    "        \n",
    "        print(f\"\\nTOP {top_k} DOCUMENTOS MÁS SIMILARES (con análisis temático):\")\n",
    "        \n",
    "        for i, idx_sim in enumerate(indices_similares):\n",
    "            metadata_sim = metadatos_enriquecidos[idx_sim]\n",
    "            sim_score = similaridades[idx_sim]\n",
    "            \n",
    "            # Analizar coincidencias\n",
    "            mismo_libro = metadata_sim['libro'] == metadata_orig['libro']\n",
    "            mismo_tema = metadata_sim['tema_principal'] == metadata_orig['tema_principal']\n",
    "            mismo_personaje = metadata_sim['personaje_principal'] == metadata_orig['personaje_principal']\n",
    "            \n",
    "            # Calcular temas en común\n",
    "            temas_comunes = set(metadata_orig['todos_temas']) & set(metadata_sim['todos_temas'])\n",
    "            personajes_comunes = set(metadata_orig['todos_personajes']) & set(metadata_sim['todos_personajes'])\n",
    "            \n",
    "            # Crear indicadores\n",
    "            indicadores = []\n",
    "            if mismo_libro:\n",
    "                indicadores.append(\"📖 MISMO LIBRO\")\n",
    "            if mismo_tema:\n",
    "                indicadores.append(\"🎭 MISMO TEMA\")\n",
    "            if mismo_personaje:\n",
    "                indicadores.append(\"👤 MISMO PERSONAJE\")\n",
    "            if temas_comunes:\n",
    "                indicadores.append(f\"🔗 TEMAS COMUNES: {list(temas_comunes)}\")\n",
    "            if personajes_comunes:\n",
    "                indicadores.append(f\"👥 PERSONAJES COMUNES: {list(personajes_comunes)}\")\n",
    "            \n",
    "            print(f\"\\n{i+1}. Similaridad: {sim_score:.4f}\")\n",
    "            print(f\"   Libro: {metadata_sim['libro']}\")\n",
    "            print(f\"   Tema: {metadata_sim['tema_principal']}\")\n",
    "            print(f\"   Personaje: {metadata_sim['personaje_principal']}\")\n",
    "            if indicadores:\n",
    "                print(f\"   Coincidencias: {' | '.join(indicadores)}\")\n",
    "            print(f\"   Texto: {textos[idx_sim][:100]}...\")\n",
    "\n",
    "# Ejecutar análisis enriquecido\n",
    "analizar_similaridad_enriquecida(indices_seleccionados, X_stephen_king, textos_stephen_king, metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27d6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División de datos:\n",
      "Train: 25 capítulos\n",
      "Test: 11 capítulos\n",
      "\n",
      "Optimizando modelos para clasificar libros de Stephen King...\n",
      "\n",
      "Probando vectorizador: tfidf_basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.2691, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 0.6476, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: tfidf_ngrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.2533, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 0.7333, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: tfidf_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: count_basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: count_ngrams\n",
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.5}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.5}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if len(textos_clf) >= 10 and len(libros_validos) >= 2:\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(etiquetas_clf)\n",
    "    \n",
    "    X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "        textos_clf, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"División de datos:\")\n",
    "    print(f\"Train: {len(X_train_clf)} capítulos\")\n",
    "    print(f\"Test: {len(X_test_clf)} capítulos\")\n",
    "    \n",
    "    vectorizers_to_test = {\n",
    "        'tfidf_basic': TfidfVectorizer(max_features=3000),\n",
    "        'tfidf_ngrams': TfidfVectorizer(ngram_range=(1, 2), max_features=4000),\n",
    "        'tfidf_filtered': TfidfVectorizer(min_df=3, max_df=0.7, max_features=3000),\n",
    "        'count_basic': CountVectorizer(max_features=3000),\n",
    "        'count_ngrams': CountVectorizer(ngram_range=(1, 2), max_features=4000)\n",
    "    }\n",
    "    \n",
    "    modelos_to_test = {\n",
    "        'MultinomialNB': MultinomialNB(),\n",
    "        'ComplementNB': ComplementNB()\n",
    "    }\n",
    "    \n",
    "    param_grids = {\n",
    "        'MultinomialNB': {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]},\n",
    "        'ComplementNB': {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "    }\n",
    "    \n",
    "    mejores_resultados = []\n",
    "    \n",
    "    print(f\"\\nOptimizando modelos para clasificar libros de Stephen King...\")\n",
    "    \n",
    "    for vec_name, vectorizer in vectorizers_to_test.items():\n",
    "        print(f\"\\nProbando vectorizador: {vec_name}\")\n",
    "        \n",
    "        # vectorizar\n",
    "        X_train_vec = vectorizer.fit_transform(X_train_clf)\n",
    "        X_test_vec = vectorizer.transform(X_test_clf)\n",
    "        \n",
    "        for model_name, modelo in modelos_to_test.items():\n",
    "            # grid search\n",
    "            grid_search = GridSearchCV(\n",
    "                modelo, param_grids[model_name], \n",
    "                cv=min(5, len(libros_validos)), \n",
    "                scoring='f1_macro',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_vec, y_train_clf)\n",
    "            \n",
    "            # predecir en test\n",
    "            y_pred = grid_search.predict(X_test_vec)\n",
    "            f1_macro = f1_score(y_test_clf, y_pred, average='macro')\n",
    "            \n",
    "            mejores_resultados.append({\n",
    "                'vectorizer': vec_name,\n",
    "                'model': model_name,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'f1_macro': f1_macro,\n",
    "                'grid_search': grid_search\n",
    "            })\n",
    "            \n",
    "            print(f\"  {model_name}: F1-macro = {f1_macro:.4f}, params = {grid_search.best_params_}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No hay suficientes datos para entrenar modelos de clasificación.\")\n",
    "    print(\"Se necesitan al menos 10 capítulos y 2 libros con mínimo 3 capítulos cada uno.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a23348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEJORES RESULTADOS DE CLASIFICACIÓN - LIBROS DE STEPHEN KING\n",
      "================================================================================\n",
      "\n",
      "1. F1-macro: 1.0000\n",
      "   Vectorizador: tfidf_filtered\n",
      "   Modelo: MultinomialNB\n",
      "   Parámetros: {'alpha': 0.1}\n",
      "\n",
      "2. F1-macro: 1.0000\n",
      "   Vectorizador: tfidf_filtered\n",
      "   Modelo: ComplementNB\n",
      "   Parámetros: {'alpha': 0.1}\n",
      "\n",
      "3. F1-macro: 1.0000\n",
      "   Vectorizador: count_basic\n",
      "   Modelo: ComplementNB\n",
      "   Parámetros: {'alpha': 0.1}\n",
      "\n",
      "4. F1-macro: 1.0000\n",
      "   Vectorizador: count_ngrams\n",
      "   Modelo: ComplementNB\n",
      "   Parámetros: {'alpha': 0.1}\n",
      "\n",
      "5. F1-macro: 0.8933\n",
      "   Vectorizador: count_basic\n",
      "   Modelo: MultinomialNB\n",
      "   Parámetros: {'alpha': 0.1}\n",
      "\n",
      "\n",
      "ANÁLISIS DETALLADO DEL MEJOR MODELO:\n",
      "Vectorizador: tfidf_filtered\n",
      "Modelo: MultinomialNB\n",
      "F1-macro: 1.0000\n",
      "\n",
      "Reporte de clasificación por libro:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "     El visitante - Stephen King       1.00      1.00      1.00         3\n",
      "   Fin de guardia - Stephen King       1.00      1.00      1.00         2\n",
      "            Holly - Stephen King       1.00      1.00      1.00         2\n",
      "      Mr Mercedes - Stephen King       1.00      1.00      1.00         2\n",
      "Quien pierde paga - Stephen King       1.00      1.00      1.00         2\n",
      "\n",
      "                        accuracy                           1.00        11\n",
      "                       macro avg       1.00      1.00      1.00        11\n",
      "                    weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "\n",
      "Análisis de errores de clasificación:\n",
      "\n",
      "Reporte de clasificación por libro:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "     El visitante - Stephen King       1.00      1.00      1.00         3\n",
      "   Fin de guardia - Stephen King       1.00      1.00      1.00         2\n",
      "            Holly - Stephen King       1.00      1.00      1.00         2\n",
      "      Mr Mercedes - Stephen King       1.00      1.00      1.00         2\n",
      "Quien pierde paga - Stephen King       1.00      1.00      1.00         2\n",
      "\n",
      "                        accuracy                           1.00        11\n",
      "                       macro avg       1.00      1.00      1.00        11\n",
      "                    weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "\n",
      "Análisis de errores de clasificación:\n"
     ]
    }
   ],
   "source": [
    "if 'mejores_resultados' in locals() and mejores_resultados:\n",
    "    mejores_resultados_sorted = sorted(mejores_resultados, key=lambda x: x['f1_macro'], reverse=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MEJORES RESULTADOS DE CLASIFICACIÓN - LIBROS DE STEPHEN KING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, resultado in enumerate(mejores_resultados_sorted[:5]):\n",
    "        print(f\"\\n{i+1}. F1-macro: {resultado['f1_macro']:.4f}\")\n",
    "        print(f\"   Vectorizador: {resultado['vectorizer']}\")\n",
    "        print(f\"   Modelo: {resultado['model']}\")\n",
    "        print(f\"   Parámetros: {resultado['best_params']}\")\n",
    "    \n",
    "    # mejor modelo\n",
    "    mejor_resultado = mejores_resultados_sorted[0]\n",
    "    mejor_grid = mejor_resultado['grid_search']\n",
    "    \n",
    "    print(f\"\\n\\nANÁLISIS DETALLADO DEL MEJOR MODELO:\")\n",
    "    print(f\"Vectorizador: {mejor_resultado['vectorizer']}\")\n",
    "    print(f\"Modelo: {mejor_resultado['model']}\")\n",
    "    print(f\"F1-macro: {mejor_resultado['f1_macro']:.4f}\")\n",
    "    \n",
    "    # reporte\n",
    "    vectorizer_name = mejor_resultado['vectorizer']\n",
    "    vectorizer_usado = vectorizers_to_test[vectorizer_name]\n",
    "    X_train_mejor = vectorizer_usado.fit_transform(X_train_clf)\n",
    "    X_test_mejor = vectorizer_usado.transform(X_test_clf)\n",
    "    \n",
    "    y_pred_mejor = mejor_grid.predict(X_test_mejor)\n",
    "    \n",
    "    print(\"\\nReporte de clasificación por libro:\")\n",
    "    print(classification_report(y_test_clf, y_pred_mejor, \n",
    "                              target_names=label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nAnálisis de errores de clasificación:\")\n",
    "    for i, (true_label, pred_label) in enumerate(zip(y_test_clf, y_pred_mejor)):\n",
    "        if true_label != pred_label:\n",
    "            libro_real = label_encoder.classes_[true_label]\n",
    "            libro_pred = label_encoder.classes_[pred_label]\n",
    "            print(f\"  Error: '{libro_real}' clasificado como '{libro_pred}'\")\n",
    "            \n",
    "else:\n",
    "    print(\"No se pudieron entrenar modelos de clasificación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129a396",
   "metadata": {},
   "source": [
    "### 3: Análisis de similaridad entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748a87e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz transpuesta (término-documento):\n",
      "Forma: (5000, 36)\n",
      "Cantidad de términos: 5000\n",
      "Cantidad de documentos (capítulos): 36\n",
      "\n",
      "Ejemplos de palabras en el vocabulario de Stephen King:\n",
      "  'once' -> índice 3312\n",
      "  'asesinado' -> índice 270\n",
      "  'pruebas' -> índice 3740\n",
      "  'flint' -> índice 1911\n",
      "  'city' -> índice 606\n",
      "  'terry' -> índice 4564\n",
      "  'maitland' -> índice 2890\n",
      "  'entrenador' -> índice 1691\n",
      "  'liga' -> índice 2727\n",
      "  'infantil' -> índice 2293\n",
      "  'profesor' -> índice 3722\n",
      "  'literatura' -> índice 2739\n",
      "  'marido' -> índice 2927\n",
      "  'ejemplar' -> índice 1378\n",
      "  'niñas' -> índice 3174\n"
     ]
    }
   ],
   "source": [
    "X_transpuesta = X_stephen_king.T\n",
    "\n",
    "print(f\"Matriz transpuesta (término-documento):\")\n",
    "print(f\"Forma: {X_transpuesta.shape}\")\n",
    "print(f\"Cantidad de términos: {X_transpuesta.shape[0]}\")\n",
    "print(f\"Cantidad de documentos (capítulos): {X_transpuesta.shape[1]}\")\n",
    "\n",
    "# indice -> palabra\n",
    "idx2word = {v: k for k, v in tfidfvect.vocabulary_.items()}\n",
    "\n",
    "print(f\"\\nEjemplos de palabras en el vocabulario de Stephen King:\")\n",
    "palabras_ejemplo = list(tfidfvect.vocabulary_.keys())[:15]\n",
    "for palabra in palabras_ejemplo:\n",
    "    idx = tfidfvect.vocabulary_[palabra]\n",
    "    print(f\"  '{palabra}' -> índice {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8419f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras seleccionadas para análisis de similaridad:\n",
      "1. 'holly' (índice: 2203, frecuencia total: 6.52)\n",
      "2. 'detective' (índice: 1240, frecuencia total: 0.12)\n",
      "3. 'hodges' (índice: 2180, frecuencia total: 6.85)\n",
      "4. 'finders' (índice: 1907, frecuencia total: 0.19)\n",
      "5. 'keepers' (índice: 2411, frecuencia total: 0.19)\n"
     ]
    }
   ],
   "source": [
    "palabras_interes = ['holly', 'detective', 'hodges', 'finders', 'keepers']\n",
    "vocabulario = tfidfvect.vocabulary_\n",
    "\n",
    "print(f\"\\nPalabras seleccionadas para análisis de similaridad:\")\n",
    "for i, palabra in enumerate(palabras_interes):\n",
    "    if palabra in vocabulario:\n",
    "        idx = vocabulario[palabra]\n",
    "        freq = np.array(X_stephen_king.sum(axis=0))[0][idx]\n",
    "        print(f\"{i+1}. '{palabra}' (índice: {idx}, frecuencia total: {freq:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f50dd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando similaridades entre palabras en los libros de Stephen King...\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - PALABRA: 'holly'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'holly'\n",
      "Frecuencia total: 6.52\n",
      "\n",
      "TOP 5 PALABRAS MÁS SIMILARES:\n",
      " 1. 'holly se' (similaridad: 0.9408, freq: 0.63)\n",
      " 2. 'holly lo' (similaridad: 0.9373, freq: 0.21)\n",
      " 3. 'holly no' (similaridad: 0.9137, freq: 0.41)\n",
      " 4. 'que holly' (similaridad: 0.9081, freq: 0.31)\n",
      " 5. 'gibney' (similaridad: 0.8938, freq: 0.51)\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - PALABRA: 'detective'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'detective'\n",
      "Frecuencia total: 0.12\n",
      "\n",
      "TOP 5 PALABRAS MÁS SIMILARES:\n",
      " 1. 'gripe' (similaridad: 0.7893, freq: 0.10)\n",
      " 2. 'le importa' (similaridad: 0.7729, freq: 0.07)\n",
      " 3. 'mensaje' (similaridad: 0.7656, freq: 0.41)\n",
      " 4. 'ella le' (similaridad: 0.7626, freq: 0.21)\n",
      " 5. 'madre se' (similaridad: 0.7524, freq: 0.08)\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - PALABRA: 'hodges'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'hodges'\n",
      "Frecuencia total: 6.85\n",
      "\n",
      "TOP 5 PALABRAS MÁS SIMILARES:\n",
      " 1. 'hodges no' (similaridad: 0.9599, freq: 0.57)\n",
      " 2. 'dice hodges' (similaridad: 0.9120, freq: 0.42)\n",
      " 3. 'hodges le' (similaridad: 0.9115, freq: 0.25)\n",
      " 4. 'de hodges' (similaridad: 0.8854, freq: 0.44)\n",
      " 5. 'nombre de' (similaridad: 0.8839, freq: 0.25)\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - PALABRA: 'finders'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'finders'\n",
      "Frecuencia total: 0.19\n",
      "\n",
      "TOP 5 PALABRAS MÁS SIMILARES:\n",
      " 1. 'finders' (similaridad: 1.0000, freq: 0.19)\n",
      " 2. 'keepers' (similaridad: 0.9993, freq: 0.19)\n",
      " 3. 'cuando holly' (similaridad: 0.8363, freq: 0.12)\n",
      " 4. 'agencia' (similaridad: 0.7951, freq: 0.17)\n",
      " 5. 'holly le' (similaridad: 0.7769, freq: 0.19)\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE SIMILARIDAD - PALABRA: 'keepers'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'keepers'\n",
      "Frecuencia total: 0.19\n",
      "\n",
      "TOP 5 PALABRAS MÁS SIMILARES:\n",
      " 1. 'finders keepers' (similaridad: 0.9993, freq: 0.19)\n",
      " 2. 'finders' (similaridad: 0.9993, freq: 0.19)\n",
      " 3. 'cuando holly' (similaridad: 0.8296, freq: 0.12)\n",
      " 4. 'agencia' (similaridad: 0.7905, freq: 0.17)\n",
      " 5. 'que holly' (similaridad: 0.7737, freq: 0.31)\n"
     ]
    }
   ],
   "source": [
    "def analizar_similaridad_palabra_stephen_king(palabra, X_transpuesta, vocabulario, idx2word, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad de una palabra con todas las demás palabras.\n",
    "    \"\"\"\n",
    "    if palabra not in vocabulario:\n",
    "        print(f\"La palabra '{palabra}' no está en el vocabulario.\")\n",
    "        return None, None\n",
    "    \n",
    "    idx_palabra = vocabulario[palabra]\n",
    "    \n",
    "    similaridades = cosine_similarity(X_transpuesta[idx_palabra], X_transpuesta)[0]\n",
    "    \n",
    "    indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANÁLISIS DE SIMILARIDAD - PALABRA: '{palabra}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    frecuencia_original = np.array(X_stephen_king.sum(axis=0))[0][idx_palabra]\n",
    "    print(f\"\\nPALABRA ORIGINAL: '{palabra}'\")\n",
    "    print(f\"Frecuencia total: {frecuencia_original:.2f}\")\n",
    "    \n",
    "    print(f\"\\nTOP {top_k} PALABRAS MÁS SIMILARES:\")\n",
    "    palabras_similares = []\n",
    "    \n",
    "    for i, idx_sim in enumerate(indices_similares):\n",
    "        palabra_similar = idx2word[idx_sim]\n",
    "        sim_score = similaridades[idx_sim]\n",
    "        frecuencia_similar = np.array(X_stephen_king.sum(axis=0))[0][idx_sim]\n",
    "        \n",
    "        print(f\"{i+1:2d}. '{palabra_similar}' (similaridad: {sim_score:.4f}, freq: {frecuencia_similar:.2f})\")\n",
    "        palabras_similares.append((palabra_similar, sim_score, frecuencia_similar))\n",
    "    \n",
    "    return indices_similares, palabras_similares\n",
    "\n",
    "resultados_palabras = {}\n",
    "\n",
    "print(\"Analizando similaridades entre palabras en los libros de Stephen King...\")\n",
    "for palabra in palabras_interes:\n",
    "    indices, similares = analizar_similaridad_palabra_stephen_king(\n",
    "        palabra, X_transpuesta, vocabulario, idx2word\n",
    "    )\n",
    "    if similares:\n",
    "        resultados_palabras[palabra] = similares"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
