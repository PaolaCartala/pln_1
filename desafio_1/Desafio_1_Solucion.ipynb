{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d584e2",
   "metadata": {},
   "source": [
    "# Desaf√≠o 1 - Soluci√≥n\n",
    "\n",
    "## Paola Cartal√°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a613f3",
   "metadata": {},
   "source": [
    "### Consigna desafio 1\n",
    "\n",
    "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos m√°s similares de cada uno analizar si tiene sentido\n",
    "la similaridad seg√∫n el contenido del texto y la etiqueta de clasificaci√≥n.\n",
    "\n",
    "**2**. Entrenar modelos de clasificaci√≥n Na√Øve Bayes para maximizar el desempe√±o de clasificaci√≥n\n",
    "(f1-score macro) en el conjunto de datos de test. Considerar cambiar par√°mteros\n",
    "de instanciaci√≥n del vectorizador y los modelos y probar modelos de Na√Øve Bayes Multinomial\n",
    "y ComplementNB.\n",
    "\n",
    "**3**. Transponer la matriz documento-t√©rmino. De esa manera se obtiene una matriz\n",
    "t√©rmino-documento que puede ser interpretada como una colecci√≥n de vectorizaci√≥n de palabras.\n",
    "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 m√°s similares. **La elecci√≥n de palabras no debe ser al azar para evitar la aparici√≥n de t√©rminos poco interpretables, elegirlas \"manualmente\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ff2e4",
   "metadata": {},
   "source": [
    "### Obtenci√≥n y procesamiento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b31a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyPDF2 numpy scikit-learn pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5ac212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971e2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(ruta_pdf):\n",
    "    \"\"\"\n",
    "    Extrae texto de un archivo PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ruta_pdf, 'rb') as archivo:\n",
    "            lector_pdf = PyPDF2.PdfReader(archivo)\n",
    "            texto_completo = \"\"\n",
    "            \n",
    "            print(f\"Procesando: {os.path.basename(ruta_pdf)} ({len(lector_pdf.pages)} p√°ginas)\")\n",
    "            \n",
    "            for pagina in tqdm(lector_pdf.pages, desc=\"Extrayendo p√°ginas\"):\n",
    "                try:\n",
    "                    texto_pagina = pagina.extract_text()\n",
    "                    if texto_pagina:\n",
    "                        texto_completo += texto_pagina + \"\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error en p√°gina: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return texto_completo\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {ruta_pdf}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6aeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_libros(carpeta_data=\"data\"):\n",
    "    \"\"\"\n",
    "    Procesa todos los libros de la carpeta data.\n",
    "    \"\"\"\n",
    "    libros = []\n",
    "    \n",
    "    patron_pdf = os.path.join(carpeta_data, \"*.pdf\")\n",
    "    archivos_pdf = glob.glob(patron_pdf)\n",
    "    \n",
    "    if not archivos_pdf:\n",
    "        print(f\"No se encontraron archivos PDF en la carpeta {carpeta_data}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Encontrados {len(archivos_pdf)} libros:\")\n",
    "    for archivo in archivos_pdf:\n",
    "        print(f\"  - {os.path.basename(archivo)}\")\n",
    "    \n",
    "    for archivo_pdf in archivos_pdf:\n",
    "        nombre_libro = os.path.splitext(os.path.basename(archivo_pdf))[0]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Procesando: {nombre_libro}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        texto = extraer_texto_pdf(archivo_pdf)\n",
    "        \n",
    "        if texto and len(texto.strip()) > 100:\n",
    "            libros.append({\n",
    "                'titulo': nombre_libro,\n",
    "                'archivo': archivo_pdf,\n",
    "                'texto': texto,\n",
    "                'num_caracteres': len(texto),\n",
    "                'num_palabras': len(texto.split())\n",
    "            })\n",
    "            print(f\"‚úì Texto extra√≠do: {len(texto):,} caracteres, {len(texto.split()):,} palabras\")\n",
    "        else:\n",
    "            print(f\"‚úó No se pudo extraer texto del archivo\")\n",
    "    \n",
    "    print(f\"\\nProcesamiento completado. {len(libros)} libros procesados exitosamente.\")\n",
    "    return libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b028927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 5 libros:\n",
      "  - El visitante - Stephen King.pdf\n",
      "  - Fin de guardia - Stephen King.pdf\n",
      "  - Holly - Stephen King.pdf\n",
      "  - Mr Mercedes - Stephen King.pdf\n",
      "  - Quien pierde paga - Stephen King.pdf\n",
      "\n",
      "============================================================\n",
      "Procesando: El visitante - Stephen King\n",
      "============================================================\n",
      "Procesando: El visitante - Stephen King.pdf (478 p√°ginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo p√°ginas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 478/478 [00:27<00:00, 17.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Texto extra√≠do: 1,000,020 caracteres, 175,368 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Fin de guardia - Stephen King\n",
      "============================================================\n",
      "Procesando: Fin de guardia - Stephen King.pdf (291 p√°ginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo p√°ginas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 291/291 [00:16<00:00, 18.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Texto extra√≠do: 731,770 caracteres, 128,323 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Holly - Stephen King\n",
      "============================================================\n",
      "Procesando: Holly - Stephen King.pdf (431 p√°ginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo p√°ginas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 431/431 [00:19<00:00, 22.00it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Texto extra√≠do: 882,615 caracteres, 157,563 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Mr Mercedes - Stephen King\n",
      "============================================================\n",
      "Procesando: Mr Mercedes - Stephen King.pdf (345 p√°ginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo p√°ginas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 345/345 [00:23<00:00, 14.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Texto extra√≠do: 851,392 caracteres, 150,535 palabras\n",
      "\n",
      "============================================================\n",
      "Procesando: Quien pierde paga - Stephen King\n",
      "============================================================\n",
      "Procesando: Quien pierde paga - Stephen King.pdf (349 p√°ginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo p√°ginas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 349/349 [00:23<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Texto extra√≠do: 784,435 caracteres, 138,061 palabras\n",
      "\n",
      "Procesamiento completado. 5 libros procesados exitosamente.\n",
      "\n",
      "Se procesaron 5 libros de Stephen King\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "libros_stephen_king = procesar_libros()\n",
    "print(f\"\\nSe procesaron {len(libros_stephen_king)} libros de Stephen King\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a03e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadatos guardados en stephen_king_metadata.json\n"
     ]
    }
   ],
   "source": [
    "libros_metadata = []\n",
    "for libro in libros_stephen_king:\n",
    "    libros_metadata.append({\n",
    "        'titulo': libro['titulo'],\n",
    "        'archivo': libro['archivo'],\n",
    "        'num_caracteres': libro['num_caracteres'],\n",
    "        'num_palabras': libro['num_palabras']\n",
    "    })\n",
    "\n",
    "with open('stephen_king_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(libros_metadata, f, ensure_ascii=False, indent=2)\n",
    "print(\"Metadatos guardados en stephen_king_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bcd217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de documentos (cap√≠tulos) para an√°lisis: 36\n"
     ]
    }
   ],
   "source": [
    "def dividir_en_capitulos(texto, titulo_libro, tama√±o_min_capitulo=2000):\n",
    "    \"\"\"\n",
    "    Divide un libro en cap√≠tulos o secciones bas√°ndose en patrones comunes.\n",
    "    \"\"\"\n",
    "    patrones_capitulo = [\n",
    "        r'\\n\\s*(?:CAP√çTULO|CAPITULO|Chapter)\\s+[IVXLCDM\\d]+[^\\n]*\\n',\n",
    "        r'\\n\\s*\\d+\\s*\\n\\n',\n",
    "        r'\\n\\s*[IVXLCDM]+\\s*\\n\\n',\n",
    "        r'\\n\\s*(?:PARTE|PART)\\s+[IVXLCDM\\d]+[^\\n]*\\n'\n",
    "    ]\n",
    "    \n",
    "    capitulos = []\n",
    "    texto_restante = texto\n",
    "    \n",
    "    for patron in patrones_capitulo:\n",
    "        divisiones = re.split(patron, texto_restante, flags=re.IGNORECASE)\n",
    "        if len(divisiones) > 2:  # Si encontr√≥ divisiones √∫tiles\n",
    "            for i, division in enumerate(divisiones):\n",
    "                if len(division.strip()) > tama√±o_min_capitulo:\n",
    "                    capitulos.append({\n",
    "                        'libro': titulo_libro,\n",
    "                        'capitulo': i + 1,\n",
    "                        'texto': division.strip()\n",
    "                    })\n",
    "            break\n",
    "    \n",
    "    if not capitulos:\n",
    "        palabras = texto.split()\n",
    "        tama√±o_chunk = 3000\n",
    "        \n",
    "        for i in range(0, len(palabras), tama√±o_chunk):\n",
    "            chunk = ' '.join(palabras[i:i + tama√±o_chunk])\n",
    "            if len(chunk.strip()) > tama√±o_min_capitulo:\n",
    "                capitulos.append({\n",
    "                    'libro': titulo_libro,\n",
    "                    'capitulo': i // tama√±o_chunk + 1,\n",
    "                    'texto': chunk.strip()\n",
    "                })\n",
    "    \n",
    "    return capitulos\n",
    "\n",
    "todos_los_documentos = []\n",
    "\n",
    "for libro in libros_stephen_king:\n",
    "    capitulos = dividir_en_capitulos(libro['texto'], libro['titulo'])\n",
    "    todos_los_documentos.extend(capitulos)\n",
    "\n",
    "print(f\"\\nTotal de documentos (cap√≠tulos) para an√°lisis: {len(todos_los_documentos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a426b",
   "metadata": {},
   "source": [
    "#### Preparaci√≥n de datos para el an√°lisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d45bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se prepararon 36 textos para an√°lisis\n"
     ]
    }
   ],
   "source": [
    "def preparar_textos(documentos):\n",
    "    \"\"\"\n",
    "    Prepara los textos de los cap√≠tulos para an√°lisis de NLP.\n",
    "    \"\"\"\n",
    "    textos = []\n",
    "    metadatos = []\n",
    "    \n",
    "    for doc in documentos:\n",
    "        texto_limpio = re.sub(r'\\s+', ' ', doc['texto']).strip()\n",
    "        \n",
    "        if len(texto_limpio) > 100:\n",
    "            textos.append(texto_limpio)\n",
    "            metadatos.append({\n",
    "                'libro': doc['libro'],\n",
    "                'capitulo': doc['capitulo'],\n",
    "                'num_palabras': len(texto_limpio.split())\n",
    "            })\n",
    "    \n",
    "    return textos, metadatos\n",
    "\n",
    "textos_stephen_king, metadatos_stephen_king = preparar_textos(todos_los_documentos)\n",
    "\n",
    "print(f\"Se prepararon {len(textos_stephen_king)} textos para an√°lisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447d602",
   "metadata": {},
   "source": [
    "### 1: Vectorizaci√≥n y an√°lisis de similaridad de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d655731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz documento-t√©rmino creada:\n",
      "Forma: (36, 5000)\n",
      "Cantidad de documentos (cap√≠tulos): 36\n",
      "Tama√±o del vocabulario: 5000\n",
      "Densidad de la matriz: 0.4904\n",
      "\n",
      "Ejemplos de t√©rminos en el vocabulario:\n",
      "['once', 'asesinado', 'pruebas', 'flint', 'city', 'terry', 'maitland', 'entrenador', 'liga', 'infantil', 'profesor', 'literatura', 'marido', 'ejemplar', 'ni√±as', 'detective', 'ralph', 'anderson', 'detenci√≥n', 'firme']\n"
     ]
    }
   ],
   "source": [
    "tfidfvect = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words=None,\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_stephen_king = tfidfvect.fit_transform(textos_stephen_king)\n",
    "\n",
    "print(f\"Matriz documento-t√©rmino creada:\")\n",
    "print(f\"Forma: {X_stephen_king.shape}\")\n",
    "print(f\"Cantidad de documentos (cap√≠tulos): {X_stephen_king.shape[0]}\")\n",
    "print(f\"Tama√±o del vocabulario: {X_stephen_king.shape[1]}\")\n",
    "print(f\"Densidad de la matriz: {X_stephen_king.nnz / (X_stephen_king.shape[0] * X_stephen_king.shape[1]):.4f}\")\n",
    "\n",
    "print(f\"\\nEjemplos de t√©rminos en el vocabulario:\")\n",
    "vocabulario_ejemplo = list(tfidfvect.vocabulary_.keys())[:20]\n",
    "print(vocabulario_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79952933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos (cap√≠tulos) seleccionados para an√°lisis de similaridad:\n",
      "\n",
      "1. Documento 35\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Palabras: 42190\n",
      "   Texto (primeros 150 chars): El Padrino , pero es tambi√©n una buena frase. Una de las mejores. Env√≠a el dinero. Se queda el cuaderno. Un cuaderno caro que meti√≥ bajo la almohada c...\n",
      "\n",
      "2. Documento 13\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 4\n",
      "   Palabras: 22203\n",
      "   Texto (primeros 150 chars): ‚ÄîAj√°. Me ha dicho que empez√≥ a notar a la se√±ora Ellerton retra√≠da‚Ä¶ ‚ÄîUn poco retra√≠da ‚Äîrectifica la se√±ora Alderson al instante‚Äî. En general, era la d...\n",
      "\n",
      "3. Documento 26\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 4\n",
      "   Palabras: 8587\n",
      "   Texto (primeros 150 chars): 17 Ese primer interrogatorio crucial, solo unas horas despu√©s del crimen. Caf√© y pastas mientras los cuerpos destrozados de los muertos eran identific...\n",
      "\n",
      "4. Documento 30\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 8\n",
      "   Palabras: 54226\n",
      "   Texto (primeros 150 chars): llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© ser...\n",
      "\n",
      "5. Documento 16\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 7\n",
      "   Palabras: 37317\n",
      "   Texto (primeros 150 chars): A juzgar por su voz, Pete parece cansado. ‚ÄîHemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste t√∫ cuando empeza...\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "indices_seleccionados = np.random.choice(len(textos_stephen_king), 5, replace=False)\n",
    "\n",
    "print(\"Documentos (cap√≠tulos) seleccionados para an√°lisis de similaridad:\")\n",
    "for i, idx in enumerate(indices_seleccionados):\n",
    "    metadata = metadatos_stephen_king[idx]\n",
    "    print(f\"\\n{i+1}. Documento {idx}\")\n",
    "    print(f\"   Libro: {metadata['libro']}\")\n",
    "    print(f\"   Cap√≠tulo: {metadata['capitulo']}\")\n",
    "    print(f\"   Palabras: {metadata['num_palabras']}\")\n",
    "    print(f\"   Texto (primeros 150 chars): {textos_stephen_king[idx][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3261cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO 35\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Quien pierde paga - Stephen King\n",
      "Cap√≠tulo: 5\n",
      "Palabras: 42190\n",
      "Texto: El Padrino , pero es tambi√©n una buena frase. Una de las mejores. Env√≠a el dinero. Se queda el cuaderno. Un cuaderno caro que meti√≥ bajo la almohada cuando la hermana menor apareci√≥ de improviso en la...\n",
      "\n",
      "TOP 5 DOCUMENTOS M√ÅS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.6663 üìñ MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Cap√≠tulo: 4\n",
      "   Texto: atenci√≥n. Me contrataron para encontrar el avi√≥n y tomar posesi√≥n de √©l. Eso es todo, punto y final. No trabajo para el FBI ni para el Departamento de...\n",
      "\n",
      "2. Similaridad: 0.5809 üìñ MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: candado enorme. Agarr√≥ de nuevo el asa, y esta vez se parti√≥. ‚Äî¬°La puta! ‚Äîexclam√≥ Pete, y se mir√≥ las manos. Las ten√≠a rojas y palpitantes. Bueno, de ...\n",
      "\n",
      "3. Similaridad: 0.5004 üìö OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 8\n",
      "   Texto: llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© ser...\n",
      "\n",
      "4. Similaridad: 0.4677 üìö OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: est√° llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. ‚ÄîPerdonen ‚Äîdice a la sala en general‚Äî. Un mensaje de texto. ‚ÄîY muy ...\n",
      "\n",
      "5. Similaridad: 0.4583 üìñ MISMO LIBRO\n",
      "   Libro: Quien pierde paga - Stephen King\n",
      "   Cap√≠tulo: 1\n",
      "   Texto: ¬´Despierta, genio¬ª. As√≠ comienza la fascinante nueva novela de Stephen King sobre un lector fan√°tico. El genio es John Rothstein, un autor de culto, c...\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO 13\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Fin de guardia - Stephen King\n",
      "Cap√≠tulo: 4\n",
      "Palabras: 22203\n",
      "Texto: ‚ÄîAj√°. Me ha dicho que empez√≥ a notar a la se√±ora Ellerton retra√≠da‚Ä¶ ‚ÄîUn poco retra√≠da ‚Äîrectifica la se√±ora Alderson al instante‚Äî. En general, era la de siempre. Rebosaba amor, igual que Marty. ‚ÄîPero a...\n",
      "\n",
      "TOP 5 DOCUMENTOS M√ÅS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.7139 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: bueno, hacerte da√±o‚Ä¶ ll√°mame. Ll√°mame inmediatamente . ‚ÄîVale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "2. Similaridad: 0.6917 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 6\n",
      "   Texto: luego se quedan vidriosos. ‚ÄîVaya aguante ‚Äîcomenta Brady, casi con afecto. Se abre una puerta. Los pasos de unos pies calzados con zapatillas se acerca...\n",
      "\n",
      "3. Similaridad: 0.6759 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 7\n",
      "   Texto: A juzgar por su voz, Pete parece cansado. ‚ÄîHemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste t√∫ cuando empeza...\n",
      "\n",
      "4. Similaridad: 0.6079 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: est√° llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. ‚ÄîPerdonen ‚Äîdice a la sala en general‚Äî. Un mensaje de texto. ‚ÄîY muy ...\n",
      "\n",
      "5. Similaridad: 0.5848 üìö OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 8\n",
      "   Texto: llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© ser...\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO 26\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Mr Mercedes - Stephen King\n",
      "Cap√≠tulo: 4\n",
      "Palabras: 8587\n",
      "Texto: 17 Ese primer interrogatorio crucial, solo unas horas despu√©s del crimen. Caf√© y pastas mientras los cuerpos destrozados de los muertos eran identificados. En alg√∫n lugar los familiares lloraban y se ...\n",
      "\n",
      "TOP 5 DOCUMENTOS M√ÅS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.6940 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: menos en la mayor√≠a de los casos. Es un don que Pete Huntley jam√°s ha pose√≠do, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n",
      "\n",
      "2. Similaridad: 0.6451 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 3\n",
      "   Texto: silencio Pete dice: ‚ÄîPues que esta vez sea una celebraci√≥n solo para hombres. ‚ÄîT√∫ mismo ‚Äîcontesta Hodges con alivio‚Äî. Esperar√© impaciente. ‚ÄîYo tambi√©n...\n",
      "\n",
      "3. Similaridad: 0.5670 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 8\n",
      "   Texto: llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© ser...\n",
      "\n",
      "4. Similaridad: 0.5065 üìö OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: est√° llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. ‚ÄîPerdonen ‚Äîdice a la sala en general‚Äî. Un mensaje de texto. ‚ÄîY muy ...\n",
      "\n",
      "5. Similaridad: 0.4817 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: televisi√≥n de acceso p√∫blico, recurso olvidado por muchos), y casualmente me enter√© de que a la noche siguiente se celebr√≥ una fiesta en el Raintree I...\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO 30\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Mr Mercedes - Stephen King\n",
      "Cap√≠tulo: 8\n",
      "Palabras: 54226\n",
      "Texto: llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© servir√≠a? Esa parte de su vida ha terminado. Pronto t...\n",
      "\n",
      "TOP 5 DOCUMENTOS M√ÅS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.7057 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: menos en la mayor√≠a de los casos. Es un don que Pete Huntley jam√°s ha pose√≠do, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n",
      "\n",
      "2. Similaridad: 0.6576 üìö OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 7\n",
      "   Texto: A juzgar por su voz, Pete parece cansado. ‚ÄîHemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste t√∫ cuando empeza...\n",
      "\n",
      "3. Similaridad: 0.6485 üìñ MISMO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 6\n",
      "   Texto: guantera. ‚ÄîCreo que las opciones de asesinato pasan por la cabeza de este individuo tan deprisa como salen los naipes de las manos de un buen repartid...\n",
      "\n",
      "4. Similaridad: 0.6484 üìö OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: bueno, hacerte da√±o‚Ä¶ ll√°mame. Ll√°mame inmediatamente . ‚ÄîVale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "5. Similaridad: 0.6328 üìö OTRO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 2\n",
      "   Texto: est√° llena. Todo el mundo se vuelve para mirarlo. Hodges siente sofoco en la cara. ‚ÄîPerdonen ‚Äîdice a la sala en general‚Äî. Un mensaje de texto. ‚ÄîY muy ...\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO 16\n",
      "======================================================================\n",
      "\n",
      "DOCUMENTO ORIGINAL:\n",
      "Libro: Fin de guardia - Stephen King\n",
      "Cap√≠tulo: 7\n",
      "Palabras: 37317\n",
      "Texto: A juzgar por su voz, Pete parece cansado. ‚ÄîHemos tenido una agarrada. Izzy y yo. Fuerte. He intentado decirle lo mismo que me dijiste t√∫ cuando empezamos a trabajar juntos: que el caso manda, y vas a ...\n",
      "\n",
      "TOP 5 DOCUMENTOS M√ÅS SIMILARES:\n",
      "\n",
      "1. Similaridad: 0.8257 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 6\n",
      "   Texto: luego se quedan vidriosos. ‚ÄîVaya aguante ‚Äîcomenta Brady, casi con afecto. Se abre una puerta. Los pasos de unos pies calzados con zapatillas se acerca...\n",
      "\n",
      "2. Similaridad: 0.7295 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: bueno, hacerte da√±o‚Ä¶ ll√°mame. Ll√°mame inmediatamente . ‚ÄîVale. Holly cruza los brazos y se lleva las manos a los hombros: un antiguo gesto de desasosie...\n",
      "\n",
      "3. Similaridad: 0.6759 üìñ MISMO LIBRO\n",
      "   Libro: Fin de guardia - Stephen King\n",
      "   Cap√≠tulo: 4\n",
      "   Texto: ‚ÄîAj√°. Me ha dicho que empez√≥ a notar a la se√±ora Ellerton retra√≠da‚Ä¶ ‚ÄîUn poco retra√≠da ‚Äîrectifica la se√±ora Alderson al instante‚Äî. En general, era la d...\n",
      "\n",
      "4. Similaridad: 0.6576 üìö OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 8\n",
      "   Texto: llegado el raticida que encarg√≥ con el alias de Ralph Jones, pero tiene la sensaci√≥n de que han pasado mil a√±os desde entonces, y de hecho ¬øde qu√© ser...\n",
      "\n",
      "5. Similaridad: 0.5503 üìö OTRO LIBRO\n",
      "   Libro: Mr Mercedes - Stephen King\n",
      "   Cap√≠tulo: 5\n",
      "   Texto: menos en la mayor√≠a de los casos. Es un don que Pete Huntley jam√°s ha pose√≠do, y a Hodges le complace sobremanera descubrir ahora que los vestigios de...\n"
     ]
    }
   ],
   "source": [
    "def analizar_similaridad_documento(idx, X, textos, metadatos, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad de un cap√≠tulo con todos los dem√°s cap√≠tulos.\n",
    "    \"\"\"\n",
    "    similaridades = cosine_similarity(X[idx], X)[0]\n",
    "    \n",
    "    indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AN√ÅLISIS DE SIMILARIDAD - DOCUMENTO {idx}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    metadata_orig = metadatos[idx]\n",
    "    print(f\"\\nDOCUMENTO ORIGINAL:\")\n",
    "    print(f\"Libro: {metadata_orig['libro']}\")\n",
    "    print(f\"Cap√≠tulo: {metadata_orig['capitulo']}\")\n",
    "    print(f\"Palabras: {metadata_orig['num_palabras']}\")\n",
    "    print(f\"Texto: {textos[idx][:200]}...\")\n",
    "    \n",
    "    print(f\"\\nTOP {top_k} DOCUMENTOS M√ÅS SIMILARES:\")\n",
    "    for i, idx_sim in enumerate(indices_similares):\n",
    "        metadata_sim = metadatos[idx_sim]\n",
    "        sim_score = similaridades[idx_sim]\n",
    "        \n",
    "        mismo_libro = metadata_sim['libro'] == metadata_orig['libro']\n",
    "        indicador = \"üìñ MISMO LIBRO\" if mismo_libro else \"üìö OTRO LIBRO\"\n",
    "        \n",
    "        print(f\"\\n{i+1}. Similaridad: {sim_score:.4f} {indicador}\")\n",
    "        print(f\"   Libro: {metadata_sim['libro']}\")\n",
    "        print(f\"   Cap√≠tulo: {metadata_sim['capitulo']}\")\n",
    "        print(f\"   Texto: {textos[idx_sim][:150]}...\")\n",
    "    \n",
    "    return indices_similares, similaridades[indices_similares]\n",
    "\n",
    "for idx in indices_seleccionados:\n",
    "    analizar_similaridad_documento(idx, X_stephen_king, textos_stephen_king, metadatos_stephen_king)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e7290",
   "metadata": {},
   "source": [
    "### 2: Optimizaci√≥n de modelos Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55926f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33cf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_clasificacion_libros(textos, metadatos, min_capitulos_por_libro=3):\n",
    "    \"\"\"\n",
    "    Prepara los datos para clasificaci√≥n por libro.\n",
    "    \"\"\"\n",
    "    conteo_libros = {}\n",
    "    for metadata in metadatos:\n",
    "        libro = metadata['libro']\n",
    "        conteo_libros[libro] = conteo_libros.get(libro, 0) + 1\n",
    "    \n",
    "    libros_validos = {libro for libro, count in conteo_libros.items() \n",
    "                     if count >= min_capitulos_por_libro}\n",
    "    \n",
    "    textos_filtrados = []\n",
    "    etiquetas = []\n",
    "    metadatos_filtrados = []\n",
    "    \n",
    "    for i, metadata in enumerate(metadatos):\n",
    "        if metadata['libro'] in libros_validos:\n",
    "            textos_filtrados.append(textos[i])\n",
    "            etiquetas.append(metadata['libro'])\n",
    "            metadatos_filtrados.append(metadata)\n",
    "    \n",
    "    return textos_filtrados, etiquetas, metadatos_filtrados, libros_validos\n",
    "\n",
    "textos_clf, etiquetas_clf, metadatos_clf, libros_validos = preparar_datos_clasificacion_libros(\n",
    "    textos_stephen_king, metadatos_stephen_king, min_capitulos_por_libro=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba1d93",
   "metadata": {},
   "source": [
    "#### An√°lisis de etiquetado tem√°tico y de personajes\n",
    "\n",
    "Vamos a enriquecer la clasificaci√≥n identificando temas y personajes principales en los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5603fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_temas_personajes(textos, metadatos):\n",
    "    \"\"\"\n",
    "    Detecta temas y personajes principales en los textos bas√°ndose en palabras clave.\n",
    "    \"\"\"\n",
    "    # Definir diccionarios de temas y personajes conocidos de Stephen King\n",
    "    temas_keywords = {\n",
    "        'horror_supernatural': ['fantasma', 'demonio', 'esp√≠ritu', 'supernatural', 'maldici√≥n', 'aparici√≥n', 'sobrenatural'],\n",
    "        'crimen_detective': ['detective', 'polic√≠a', 'asesino', 'crimen', 'investigaci√≥n', 'homicidio', 'caso'],\n",
    "        'psicol√≥gico': ['mente', 'loco', 'psic√≥logo', 'mental', 'locura', 'cerebro', 'pensamiento'],\n",
    "        'terror_urbano': ['ciudad', 'calle', 'hospital', 'hotel', 'edificio', 'urbano'],\n",
    "        'muerte_violencia': ['muerte', 'sangre', 'matar', 'violencia', 'cad√°ver', 'asesinato']\n",
    "    }\n",
    "    \n",
    "    personajes_keywords = {\n",
    "        'bill_hodges': ['hodges', 'bill', 'detective hodges', 'william hodges'],\n",
    "        'holly_gibney': ['holly', 'gibney', 'holly gibney'],\n",
    "        'jerome_robinson': ['jerome', 'robinson'],\n",
    "        'brady_hartsfield': ['brady', 'hartsfield', 'mr mercedes'],\n",
    "        'ralph_anderson': ['ralph', 'anderson'],\n",
    "        'el_visitante': ['visitante', 'outsider', 'extra√±o']\n",
    "    }\n",
    "    \n",
    "    textos_etiquetados = []\n",
    "    \n",
    "    for i, texto in enumerate(textos):\n",
    "        texto_lower = texto.lower()\n",
    "        metadata = metadatos[i].copy()\n",
    "        \n",
    "        # Detectar temas\n",
    "        temas_detectados = []\n",
    "        for tema, keywords in temas_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in texto_lower)\n",
    "            if score > 0:\n",
    "                temas_detectados.append((tema, score))\n",
    "        \n",
    "        # Detectar personajes\n",
    "        personajes_detectados = []\n",
    "        for personaje, keywords in personajes_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in texto_lower)\n",
    "            if score > 0:\n",
    "                personajes_detectados.append((personaje, score))\n",
    "        \n",
    "        # Ordenar por relevancia\n",
    "        temas_detectados.sort(key=lambda x: x[1], reverse=True)\n",
    "        personajes_detectados.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Agregar etiquetas al metadata\n",
    "        metadata['tema_principal'] = temas_detectados[0][0] if temas_detectados else 'general'\n",
    "        metadata['todos_temas'] = [t[0] for t in temas_detectados]\n",
    "        metadata['personaje_principal'] = personajes_detectados[0][0] if personajes_detectados else 'otros'\n",
    "        metadata['todos_personajes'] = [p[0] for p in personajes_detectados]\n",
    "        \n",
    "        textos_etiquetados.append(metadata)\n",
    "    \n",
    "    return textos_etiquetados\n",
    "\n",
    "# Aplicar etiquetado tem√°tico\n",
    "metadatos_enriquecidos = detectar_temas_personajes(textos_stephen_king, metadatos_stephen_king)\n",
    "\n",
    "print(\"An√°lisis de etiquetado tem√°tico y de personajes completado\")\n",
    "print(f\"Ejemplo de metadatos enriquecidos:\")\n",
    "for i in range(min(3, len(metadatos_enriquecidos))):\n",
    "    meta = metadatos_enriquecidos[i]\n",
    "    print(f\"\\nCap√≠tulo {i+1}:\")\n",
    "    print(f\"  Libro: {meta['libro']}\")\n",
    "    print(f\"  Tema principal: {meta['tema_principal']}\")\n",
    "    print(f\"  Personaje principal: {meta['personaje_principal']}\")\n",
    "    print(f\"  Todos los temas: {meta['todos_temas']}\")\n",
    "    print(f\"  Todos los personajes: {meta['todos_personajes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_distribucion_etiquetas(metadatos_enriquecidos):\n",
    "    \"\"\"\n",
    "    Analiza la distribuci√≥n de temas y personajes en el corpus.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Contar temas principales\n",
    "    temas_principales = [meta['tema_principal'] for meta in metadatos_enriquecidos]\n",
    "    contador_temas = Counter(temas_principales)\n",
    "    \n",
    "    # Contar personajes principales\n",
    "    personajes_principales = [meta['personaje_principal'] for meta in metadatos_enriquecidos]\n",
    "    contador_personajes = Counter(personajes_principales)\n",
    "    \n",
    "    # Contar todos los temas (m√∫ltiple por documento)\n",
    "    todos_temas = []\n",
    "    for meta in metadatos_enriquecidos:\n",
    "        todos_temas.extend(meta['todos_temas'])\n",
    "    contador_todos_temas = Counter(todos_temas)\n",
    "    \n",
    "    # Contar todos los personajes (m√∫ltiple por documento)\n",
    "    todos_personajes = []\n",
    "    for meta in metadatos_enriquecidos:\n",
    "        todos_personajes.extend(meta['todos_personajes'])\n",
    "    contador_todos_personajes = Counter(todos_personajes)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"DISTRIBUCI√ìN DE TEMAS Y PERSONAJES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nTEMAS PRINCIPALES (uno por cap√≠tulo):\")\n",
    "    for tema, count in contador_temas.most_common():\n",
    "        porcentaje = (count / len(metadatos_enriquecidos)) * 100\n",
    "        print(f\"  {tema}: {count} cap√≠tulos ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nPERSONAJES PRINCIPALES (uno por cap√≠tulo):\")\n",
    "    for personaje, count in contador_personajes.most_common():\n",
    "        porcentaje = (count / len(metadatos_enriquecidos)) * 100\n",
    "        print(f\"  {personaje}: {count} cap√≠tulos ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTODOS LOS TEMAS DETECTADOS (m√∫ltiples por cap√≠tulo):\")\n",
    "    for tema, count in contador_todos_temas.most_common():\n",
    "        print(f\"  {tema}: {count} menciones\")\n",
    "    \n",
    "    print(f\"\\nTODOS LOS PERSONAJES DETECTADOS (m√∫ltiples por cap√≠tulo):\")\n",
    "    for personaje, count in contador_todos_personajes.most_common():\n",
    "        print(f\"  {personaje}: {count} menciones\")\n",
    "    \n",
    "    return contador_temas, contador_personajes\n",
    "\n",
    "# Analizar distribuci√≥n\n",
    "dist_temas, dist_personajes = analizar_distribucion_etiquetas(metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_clasificadores_enriquecidos(textos, metadatos_enriquecidos):\n",
    "    \"\"\"\n",
    "    Entrena clasificadores para temas y personajes adem√°s de libros.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLASIFICACI√ìN ENRIQUECIDA: TEMAS Y PERSONAJES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Preparar datos para clasificaci√≥n por tema\n",
    "    temas = [meta['tema_principal'] for meta in metadatos_enriquecidos]\n",
    "    temas_unicos = list(set(temas))\n",
    "    \n",
    "    if len(temas_unicos) >= 2:\n",
    "        print(f\"\\nClasificaci√≥n por TEMA:\")\n",
    "        print(f\"Temas disponibles: {temas_unicos}\")\n",
    "        \n",
    "        # Filtrar solo temas con suficientes ejemplos\n",
    "        from collections import Counter\n",
    "        contador_temas = Counter(temas)\n",
    "        temas_validos = [tema for tema, count in contador_temas.items() if count >= 3]\n",
    "        \n",
    "        if len(temas_validos) >= 2:\n",
    "            textos_tema = []\n",
    "            etiquetas_tema = []\n",
    "            \n",
    "            for i, meta in enumerate(metadatos_enriquecidos):\n",
    "                if meta['tema_principal'] in temas_validos:\n",
    "                    textos_tema.append(textos[i])\n",
    "                    etiquetas_tema.append(meta['tema_principal'])\n",
    "            \n",
    "            if len(textos_tema) >= 10:\n",
    "                # Entrenar clasificador de temas\n",
    "                label_encoder_tema = LabelEncoder()\n",
    "                y_tema_encoded = label_encoder_tema.fit_transform(etiquetas_tema)\n",
    "                \n",
    "                X_train_tema, X_test_tema, y_train_tema, y_test_tema = train_test_split(\n",
    "                    textos_tema, y_tema_encoded, test_size=0.3, random_state=42, stratify=y_tema_encoded\n",
    "                )\n",
    "                \n",
    "                # Vectorizar y entrenar\n",
    "                vectorizer_tema = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "                X_train_tema_vec = vectorizer_tema.fit_transform(X_train_tema)\n",
    "                X_test_tema_vec = vectorizer_tema.transform(X_test_tema)\n",
    "                \n",
    "                # Probar modelos\n",
    "                modelo_tema = MultinomialNB(alpha=1.0)\n",
    "                modelo_tema.fit(X_train_tema_vec, y_train_tema)\n",
    "                \n",
    "                y_pred_tema = modelo_tema.predict(X_test_tema_vec)\n",
    "                f1_tema = f1_score(y_test_tema, y_pred_tema, average='macro')\n",
    "                \n",
    "                print(f\"F1-score para clasificaci√≥n de temas: {f1_tema:.4f}\")\n",
    "                print(\"Reporte de clasificaci√≥n de temas:\")\n",
    "                print(classification_report(y_test_tema, y_pred_tema, \n",
    "                                          target_names=label_encoder_tema.classes_))\n",
    "        else:\n",
    "            print(\"No hay suficientes temas con ejemplos m√≠nimos para entrenar.\")\n",
    "    \n",
    "    # Preparar datos para clasificaci√≥n por personaje\n",
    "    personajes = [meta['personaje_principal'] for meta in metadatos_enriquecidos]\n",
    "    personajes_unicos = list(set(personajes))\n",
    "    \n",
    "    if len(personajes_unicos) >= 2:\n",
    "        print(f\"\\nClasificaci√≥n por PERSONAJE:\")\n",
    "        print(f\"Personajes disponibles: {personajes_unicos}\")\n",
    "        \n",
    "        # Filtrar solo personajes con suficientes ejemplos\n",
    "        contador_personajes = Counter(personajes)\n",
    "        personajes_validos = [personaje for personaje, count in contador_personajes.items() if count >= 3]\n",
    "        \n",
    "        if len(personajes_validos) >= 2:\n",
    "            textos_personaje = []\n",
    "            etiquetas_personaje = []\n",
    "            \n",
    "            for i, meta in enumerate(metadatos_enriquecidos):\n",
    "                if meta['personaje_principal'] in personajes_validos:\n",
    "                    textos_personaje.append(textos[i])\n",
    "                    etiquetas_personaje.append(meta['personaje_principal'])\n",
    "            \n",
    "            if len(textos_personaje) >= 10:\n",
    "                # Entrenar clasificador de personajes\n",
    "                label_encoder_personaje = LabelEncoder()\n",
    "                y_personaje_encoded = label_encoder_personaje.fit_transform(etiquetas_personaje)\n",
    "                \n",
    "                X_train_pers, X_test_pers, y_train_pers, y_test_pers = train_test_split(\n",
    "                    textos_personaje, y_personaje_encoded, test_size=0.3, random_state=42, stratify=y_personaje_encoded\n",
    "                )\n",
    "                \n",
    "                # Vectorizar y entrenar\n",
    "                vectorizer_personaje = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "                X_train_pers_vec = vectorizer_personaje.fit_transform(X_train_pers)\n",
    "                X_test_pers_vec = vectorizer_personaje.transform(X_test_pers)\n",
    "                \n",
    "                # Probar modelos\n",
    "                modelo_personaje = MultinomialNB(alpha=1.0)\n",
    "                modelo_personaje.fit(X_train_pers_vec, y_train_pers)\n",
    "                \n",
    "                y_pred_personaje = modelo_personaje.predict(X_test_pers_vec)\n",
    "                f1_personaje = f1_score(y_test_pers, y_pred_personaje, average='macro')\n",
    "                \n",
    "                print(f\"F1-score para clasificaci√≥n de personajes: {f1_personaje:.4f}\")\n",
    "                print(\"Reporte de clasificaci√≥n de personajes:\")\n",
    "                print(classification_report(y_test_pers, y_pred_personaje, \n",
    "                                          target_names=label_encoder_personaje.classes_))\n",
    "        else:\n",
    "            print(\"No hay suficientes personajes con ejemplos m√≠nimos para entrenar.\")\n",
    "\n",
    "# Entrenar clasificadores enriquecidos\n",
    "entrenar_clasificadores_enriquecidos(textos_stephen_king, metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742428ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_similaridad_enriquecida(indices_seleccionados, X, textos, metadatos_enriquecidos, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad considerando las etiquetas tem√°ticas y de personajes.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AN√ÅLISIS DE SIMILARIDAD ENRIQUECIDO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for idx in indices_seleccionados:\n",
    "        similaridades = cosine_similarity(X[idx], X)[0]\n",
    "        indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DOCUMENTO {idx} - AN√ÅLISIS ENRIQUECIDO\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        metadata_orig = metadatos_enriquecidos[idx]\n",
    "        print(f\"\\nDOCUMENTO ORIGINAL:\")\n",
    "        print(f\"Libro: {metadata_orig['libro']}\")\n",
    "        print(f\"Cap√≠tulo: {metadata_orig['capitulo']}\")\n",
    "        print(f\"Tema principal: {metadata_orig['tema_principal']}\")\n",
    "        print(f\"Personaje principal: {metadata_orig['personaje_principal']}\")\n",
    "        print(f\"Todos los temas: {metadata_orig['todos_temas']}\")\n",
    "        print(f\"Texto: {textos[idx][:150]}...\")\n",
    "        \n",
    "        print(f\"\\nTOP {top_k} DOCUMENTOS M√ÅS SIMILARES (con an√°lisis tem√°tico):\")\n",
    "        \n",
    "        for i, idx_sim in enumerate(indices_similares):\n",
    "            metadata_sim = metadatos_enriquecidos[idx_sim]\n",
    "            sim_score = similaridades[idx_sim]\n",
    "            \n",
    "            # Analizar coincidencias\n",
    "            mismo_libro = metadata_sim['libro'] == metadata_orig['libro']\n",
    "            mismo_tema = metadata_sim['tema_principal'] == metadata_orig['tema_principal']\n",
    "            mismo_personaje = metadata_sim['personaje_principal'] == metadata_orig['personaje_principal']\n",
    "            \n",
    "            # Calcular temas en com√∫n\n",
    "            temas_comunes = set(metadata_orig['todos_temas']) & set(metadata_sim['todos_temas'])\n",
    "            personajes_comunes = set(metadata_orig['todos_personajes']) & set(metadata_sim['todos_personajes'])\n",
    "            \n",
    "            # Crear indicadores\n",
    "            indicadores = []\n",
    "            if mismo_libro:\n",
    "                indicadores.append(\"üìñ MISMO LIBRO\")\n",
    "            if mismo_tema:\n",
    "                indicadores.append(\"üé≠ MISMO TEMA\")\n",
    "            if mismo_personaje:\n",
    "                indicadores.append(\"üë§ MISMO PERSONAJE\")\n",
    "            if temas_comunes:\n",
    "                indicadores.append(f\"üîó TEMAS COMUNES: {list(temas_comunes)}\")\n",
    "            if personajes_comunes:\n",
    "                indicadores.append(f\"üë• PERSONAJES COMUNES: {list(personajes_comunes)}\")\n",
    "            \n",
    "            print(f\"\\n{i+1}. Similaridad: {sim_score:.4f}\")\n",
    "            print(f\"   Libro: {metadata_sim['libro']}\")\n",
    "            print(f\"   Tema: {metadata_sim['tema_principal']}\")\n",
    "            print(f\"   Personaje: {metadata_sim['personaje_principal']}\")\n",
    "            if indicadores:\n",
    "                print(f\"   Coincidencias: {' | '.join(indicadores)}\")\n",
    "            print(f\"   Texto: {textos[idx_sim][:100]}...\")\n",
    "\n",
    "# Ejecutar an√°lisis enriquecido\n",
    "analizar_similaridad_enriquecida(indices_seleccionados, X_stephen_king, textos_stephen_king, metadatos_enriquecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27d6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisi√≥n de datos:\n",
      "Train: 25 cap√≠tulos\n",
      "Test: 11 cap√≠tulos\n",
      "\n",
      "Optimizando modelos para clasificar libros de Stephen King...\n",
      "\n",
      "Probando vectorizador: tfidf_basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.2691, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 0.6476, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: tfidf_ngrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.2533, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 0.7333, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: tfidf_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: count_basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.1}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "\n",
      "Probando vectorizador: count_ngrams\n",
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.5}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n",
      "  MultinomialNB: F1-macro = 0.8933, params = {'alpha': 0.5}\n",
      "  ComplementNB: F1-macro = 1.0000, params = {'alpha': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/paoc3/OneDrive/Documents/Especializacion en IA/Septimo bimestre/pln_1/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if len(textos_clf) >= 10 and len(libros_validos) >= 2:\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(etiquetas_clf)\n",
    "    \n",
    "    X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "        textos_clf, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"Divisi√≥n de datos:\")\n",
    "    print(f\"Train: {len(X_train_clf)} cap√≠tulos\")\n",
    "    print(f\"Test: {len(X_test_clf)} cap√≠tulos\")\n",
    "    \n",
    "    vectorizers_to_test = {\n",
    "        'tfidf_basic': TfidfVectorizer(max_features=3000),\n",
    "        'tfidf_ngrams': TfidfVectorizer(ngram_range=(1, 2), max_features=4000),\n",
    "        'tfidf_filtered': TfidfVectorizer(min_df=3, max_df=0.7, max_features=3000),\n",
    "        'count_basic': CountVectorizer(max_features=3000),\n",
    "        'count_ngrams': CountVectorizer(ngram_range=(1, 2), max_features=4000)\n",
    "    }\n",
    "    \n",
    "    modelos_to_test = {\n",
    "        'MultinomialNB': MultinomialNB(),\n",
    "        'ComplementNB': ComplementNB()\n",
    "    }\n",
    "    \n",
    "    param_grids = {\n",
    "        'MultinomialNB': {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]},\n",
    "        'ComplementNB': {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "    }\n",
    "    \n",
    "    mejores_resultados = []\n",
    "    \n",
    "    print(f\"\\nOptimizando modelos para clasificar libros de Stephen King...\")\n",
    "    \n",
    "    for vec_name, vectorizer in vectorizers_to_test.items():\n",
    "        print(f\"\\nProbando vectorizador: {vec_name}\")\n",
    "        \n",
    "        # vectorizar\n",
    "        X_train_vec = vectorizer.fit_transform(X_train_clf)\n",
    "        X_test_vec = vectorizer.transform(X_test_clf)\n",
    "        \n",
    "        for model_name, modelo in modelos_to_test.items():\n",
    "            # grid search\n",
    "            grid_search = GridSearchCV(\n",
    "                modelo, param_grids[model_name], \n",
    "                cv=min(5, len(libros_validos)), \n",
    "                scoring='f1_macro',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_vec, y_train_clf)\n",
    "            \n",
    "            # predecir en test\n",
    "            y_pred = grid_search.predict(X_test_vec)\n",
    "            f1_macro = f1_score(y_test_clf, y_pred, average='macro')\n",
    "            \n",
    "            mejores_resultados.append({\n",
    "                'vectorizer': vec_name,\n",
    "                'model': model_name,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'f1_macro': f1_macro,\n",
    "                'grid_search': grid_search\n",
    "            })\n",
    "            \n",
    "            print(f\"  {model_name}: F1-macro = {f1_macro:.4f}, params = {grid_search.best_params_}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No hay suficientes datos para entrenar modelos de clasificaci√≥n.\")\n",
    "    print(\"Se necesitan al menos 10 cap√≠tulos y 2 libros con m√≠nimo 3 cap√≠tulos cada uno.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a23348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEJORES RESULTADOS DE CLASIFICACI√ìN - LIBROS DE STEPHEN KING\n",
      "================================================================================\n",
      "\n",
      "1. F1-macro: 1.0000\n",
      "   Vectorizador: tfidf_filtered\n",
      "   Modelo: MultinomialNB\n",
      "   Par√°metros: {'alpha': 0.1}\n",
      "\n",
      "2. F1-macro: 1.0000\n",
      "   Vectorizador: tfidf_filtered\n",
      "   Modelo: ComplementNB\n",
      "   Par√°metros: {'alpha': 0.1}\n",
      "\n",
      "3. F1-macro: 1.0000\n",
      "   Vectorizador: count_basic\n",
      "   Modelo: ComplementNB\n",
      "   Par√°metros: {'alpha': 0.1}\n",
      "\n",
      "4. F1-macro: 1.0000\n",
      "   Vectorizador: count_ngrams\n",
      "   Modelo: ComplementNB\n",
      "   Par√°metros: {'alpha': 0.1}\n",
      "\n",
      "5. F1-macro: 0.8933\n",
      "   Vectorizador: count_basic\n",
      "   Modelo: MultinomialNB\n",
      "   Par√°metros: {'alpha': 0.1}\n",
      "\n",
      "\n",
      "AN√ÅLISIS DETALLADO DEL MEJOR MODELO:\n",
      "Vectorizador: tfidf_filtered\n",
      "Modelo: MultinomialNB\n",
      "F1-macro: 1.0000\n",
      "\n",
      "Reporte de clasificaci√≥n por libro:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "     El visitante - Stephen King       1.00      1.00      1.00         3\n",
      "   Fin de guardia - Stephen King       1.00      1.00      1.00         2\n",
      "            Holly - Stephen King       1.00      1.00      1.00         2\n",
      "      Mr Mercedes - Stephen King       1.00      1.00      1.00         2\n",
      "Quien pierde paga - Stephen King       1.00      1.00      1.00         2\n",
      "\n",
      "                        accuracy                           1.00        11\n",
      "                       macro avg       1.00      1.00      1.00        11\n",
      "                    weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "\n",
      "An√°lisis de errores de clasificaci√≥n:\n",
      "\n",
      "Reporte de clasificaci√≥n por libro:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "     El visitante - Stephen King       1.00      1.00      1.00         3\n",
      "   Fin de guardia - Stephen King       1.00      1.00      1.00         2\n",
      "            Holly - Stephen King       1.00      1.00      1.00         2\n",
      "      Mr Mercedes - Stephen King       1.00      1.00      1.00         2\n",
      "Quien pierde paga - Stephen King       1.00      1.00      1.00         2\n",
      "\n",
      "                        accuracy                           1.00        11\n",
      "                       macro avg       1.00      1.00      1.00        11\n",
      "                    weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "\n",
      "An√°lisis de errores de clasificaci√≥n:\n"
     ]
    }
   ],
   "source": [
    "if 'mejores_resultados' in locals() and mejores_resultados:\n",
    "    mejores_resultados_sorted = sorted(mejores_resultados, key=lambda x: x['f1_macro'], reverse=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MEJORES RESULTADOS DE CLASIFICACI√ìN - LIBROS DE STEPHEN KING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, resultado in enumerate(mejores_resultados_sorted[:5]):\n",
    "        print(f\"\\n{i+1}. F1-macro: {resultado['f1_macro']:.4f}\")\n",
    "        print(f\"   Vectorizador: {resultado['vectorizer']}\")\n",
    "        print(f\"   Modelo: {resultado['model']}\")\n",
    "        print(f\"   Par√°metros: {resultado['best_params']}\")\n",
    "    \n",
    "    # mejor modelo\n",
    "    mejor_resultado = mejores_resultados_sorted[0]\n",
    "    mejor_grid = mejor_resultado['grid_search']\n",
    "    \n",
    "    print(f\"\\n\\nAN√ÅLISIS DETALLADO DEL MEJOR MODELO:\")\n",
    "    print(f\"Vectorizador: {mejor_resultado['vectorizer']}\")\n",
    "    print(f\"Modelo: {mejor_resultado['model']}\")\n",
    "    print(f\"F1-macro: {mejor_resultado['f1_macro']:.4f}\")\n",
    "    \n",
    "    # reporte\n",
    "    vectorizer_name = mejor_resultado['vectorizer']\n",
    "    vectorizer_usado = vectorizers_to_test[vectorizer_name]\n",
    "    X_train_mejor = vectorizer_usado.fit_transform(X_train_clf)\n",
    "    X_test_mejor = vectorizer_usado.transform(X_test_clf)\n",
    "    \n",
    "    y_pred_mejor = mejor_grid.predict(X_test_mejor)\n",
    "    \n",
    "    print(\"\\nReporte de clasificaci√≥n por libro:\")\n",
    "    print(classification_report(y_test_clf, y_pred_mejor, \n",
    "                              target_names=label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nAn√°lisis de errores de clasificaci√≥n:\")\n",
    "    for i, (true_label, pred_label) in enumerate(zip(y_test_clf, y_pred_mejor)):\n",
    "        if true_label != pred_label:\n",
    "            libro_real = label_encoder.classes_[true_label]\n",
    "            libro_pred = label_encoder.classes_[pred_label]\n",
    "            print(f\"  Error: '{libro_real}' clasificado como '{libro_pred}'\")\n",
    "            \n",
    "else:\n",
    "    print(\"No se pudieron entrenar modelos de clasificaci√≥n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129a396",
   "metadata": {},
   "source": [
    "### 3: An√°lisis de similaridad entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748a87e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz transpuesta (t√©rmino-documento):\n",
      "Forma: (5000, 36)\n",
      "Cantidad de t√©rminos: 5000\n",
      "Cantidad de documentos (cap√≠tulos): 36\n",
      "\n",
      "Ejemplos de palabras en el vocabulario de Stephen King:\n",
      "  'once' -> √≠ndice 3312\n",
      "  'asesinado' -> √≠ndice 270\n",
      "  'pruebas' -> √≠ndice 3740\n",
      "  'flint' -> √≠ndice 1911\n",
      "  'city' -> √≠ndice 606\n",
      "  'terry' -> √≠ndice 4564\n",
      "  'maitland' -> √≠ndice 2890\n",
      "  'entrenador' -> √≠ndice 1691\n",
      "  'liga' -> √≠ndice 2727\n",
      "  'infantil' -> √≠ndice 2293\n",
      "  'profesor' -> √≠ndice 3722\n",
      "  'literatura' -> √≠ndice 2739\n",
      "  'marido' -> √≠ndice 2927\n",
      "  'ejemplar' -> √≠ndice 1378\n",
      "  'ni√±as' -> √≠ndice 3174\n"
     ]
    }
   ],
   "source": [
    "X_transpuesta = X_stephen_king.T\n",
    "\n",
    "print(f\"Matriz transpuesta (t√©rmino-documento):\")\n",
    "print(f\"Forma: {X_transpuesta.shape}\")\n",
    "print(f\"Cantidad de t√©rminos: {X_transpuesta.shape[0]}\")\n",
    "print(f\"Cantidad de documentos (cap√≠tulos): {X_transpuesta.shape[1]}\")\n",
    "\n",
    "# indice -> palabra\n",
    "idx2word = {v: k for k, v in tfidfvect.vocabulary_.items()}\n",
    "\n",
    "print(f\"\\nEjemplos de palabras en el vocabulario de Stephen King:\")\n",
    "palabras_ejemplo = list(tfidfvect.vocabulary_.keys())[:15]\n",
    "for palabra in palabras_ejemplo:\n",
    "    idx = tfidfvect.vocabulary_[palabra]\n",
    "    print(f\"  '{palabra}' -> √≠ndice {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8419f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras seleccionadas para an√°lisis de similaridad:\n",
      "1. 'holly' (√≠ndice: 2203, frecuencia total: 6.52)\n",
      "2. 'detective' (√≠ndice: 1240, frecuencia total: 0.12)\n",
      "3. 'hodges' (√≠ndice: 2180, frecuencia total: 6.85)\n",
      "4. 'finders' (√≠ndice: 1907, frecuencia total: 0.19)\n",
      "5. 'keepers' (√≠ndice: 2411, frecuencia total: 0.19)\n"
     ]
    }
   ],
   "source": [
    "palabras_interes = ['holly', 'detective', 'hodges', 'finders', 'keepers']\n",
    "vocabulario = tfidfvect.vocabulary_\n",
    "\n",
    "print(f\"\\nPalabras seleccionadas para an√°lisis de similaridad:\")\n",
    "for i, palabra in enumerate(palabras_interes):\n",
    "    if palabra in vocabulario:\n",
    "        idx = vocabulario[palabra]\n",
    "        freq = np.array(X_stephen_king.sum(axis=0))[0][idx]\n",
    "        print(f\"{i+1}. '{palabra}' (√≠ndice: {idx}, frecuencia total: {freq:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f50dd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando similaridades entre palabras en los libros de Stephen King...\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - PALABRA: 'holly'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'holly'\n",
      "Frecuencia total: 6.52\n",
      "\n",
      "TOP 5 PALABRAS M√ÅS SIMILARES:\n",
      " 1. 'holly se' (similaridad: 0.9408, freq: 0.63)\n",
      " 2. 'holly lo' (similaridad: 0.9373, freq: 0.21)\n",
      " 3. 'holly no' (similaridad: 0.9137, freq: 0.41)\n",
      " 4. 'que holly' (similaridad: 0.9081, freq: 0.31)\n",
      " 5. 'gibney' (similaridad: 0.8938, freq: 0.51)\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - PALABRA: 'detective'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'detective'\n",
      "Frecuencia total: 0.12\n",
      "\n",
      "TOP 5 PALABRAS M√ÅS SIMILARES:\n",
      " 1. 'gripe' (similaridad: 0.7893, freq: 0.10)\n",
      " 2. 'le importa' (similaridad: 0.7729, freq: 0.07)\n",
      " 3. 'mensaje' (similaridad: 0.7656, freq: 0.41)\n",
      " 4. 'ella le' (similaridad: 0.7626, freq: 0.21)\n",
      " 5. 'madre se' (similaridad: 0.7524, freq: 0.08)\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - PALABRA: 'hodges'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'hodges'\n",
      "Frecuencia total: 6.85\n",
      "\n",
      "TOP 5 PALABRAS M√ÅS SIMILARES:\n",
      " 1. 'hodges no' (similaridad: 0.9599, freq: 0.57)\n",
      " 2. 'dice hodges' (similaridad: 0.9120, freq: 0.42)\n",
      " 3. 'hodges le' (similaridad: 0.9115, freq: 0.25)\n",
      " 4. 'de hodges' (similaridad: 0.8854, freq: 0.44)\n",
      " 5. 'nombre de' (similaridad: 0.8839, freq: 0.25)\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - PALABRA: 'finders'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'finders'\n",
      "Frecuencia total: 0.19\n",
      "\n",
      "TOP 5 PALABRAS M√ÅS SIMILARES:\n",
      " 1. 'finders' (similaridad: 1.0000, freq: 0.19)\n",
      " 2. 'keepers' (similaridad: 0.9993, freq: 0.19)\n",
      " 3. 'cuando holly' (similaridad: 0.8363, freq: 0.12)\n",
      " 4. 'agencia' (similaridad: 0.7951, freq: 0.17)\n",
      " 5. 'holly le' (similaridad: 0.7769, freq: 0.19)\n",
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE SIMILARIDAD - PALABRA: 'keepers'\n",
      "======================================================================\n",
      "\n",
      "PALABRA ORIGINAL: 'keepers'\n",
      "Frecuencia total: 0.19\n",
      "\n",
      "TOP 5 PALABRAS M√ÅS SIMILARES:\n",
      " 1. 'finders keepers' (similaridad: 0.9993, freq: 0.19)\n",
      " 2. 'finders' (similaridad: 0.9993, freq: 0.19)\n",
      " 3. 'cuando holly' (similaridad: 0.8296, freq: 0.12)\n",
      " 4. 'agencia' (similaridad: 0.7905, freq: 0.17)\n",
      " 5. 'que holly' (similaridad: 0.7737, freq: 0.31)\n"
     ]
    }
   ],
   "source": [
    "def analizar_similaridad_palabra_stephen_king(palabra, X_transpuesta, vocabulario, idx2word, top_k=5):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad de una palabra con todas las dem√°s palabras.\n",
    "    \"\"\"\n",
    "    if palabra not in vocabulario:\n",
    "        print(f\"La palabra '{palabra}' no est√° en el vocabulario.\")\n",
    "        return None, None\n",
    "    \n",
    "    idx_palabra = vocabulario[palabra]\n",
    "    \n",
    "    similaridades = cosine_similarity(X_transpuesta[idx_palabra], X_transpuesta)[0]\n",
    "    \n",
    "    indices_similares = np.argsort(similaridades)[::-1][1:top_k+1]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AN√ÅLISIS DE SIMILARIDAD - PALABRA: '{palabra}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    frecuencia_original = np.array(X_stephen_king.sum(axis=0))[0][idx_palabra]\n",
    "    print(f\"\\nPALABRA ORIGINAL: '{palabra}'\")\n",
    "    print(f\"Frecuencia total: {frecuencia_original:.2f}\")\n",
    "    \n",
    "    print(f\"\\nTOP {top_k} PALABRAS M√ÅS SIMILARES:\")\n",
    "    palabras_similares = []\n",
    "    \n",
    "    for i, idx_sim in enumerate(indices_similares):\n",
    "        palabra_similar = idx2word[idx_sim]\n",
    "        sim_score = similaridades[idx_sim]\n",
    "        frecuencia_similar = np.array(X_stephen_king.sum(axis=0))[0][idx_sim]\n",
    "        \n",
    "        print(f\"{i+1:2d}. '{palabra_similar}' (similaridad: {sim_score:.4f}, freq: {frecuencia_similar:.2f})\")\n",
    "        palabras_similares.append((palabra_similar, sim_score, frecuencia_similar))\n",
    "    \n",
    "    return indices_similares, palabras_similares\n",
    "\n",
    "resultados_palabras = {}\n",
    "\n",
    "print(\"Analizando similaridades entre palabras en los libros de Stephen King...\")\n",
    "for palabra in palabras_interes:\n",
    "    indices, similares = analizar_similaridad_palabra_stephen_king(\n",
    "        palabra, X_transpuesta, vocabulario, idx2word\n",
    "    )\n",
    "    if similares:\n",
    "        resultados_palabras[palabra] = similares"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
